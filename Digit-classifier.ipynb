{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as random\n",
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, currentLayerLen):\n",
    "        self.activationVector = np.array([random.uniform(0, 0.1) for i in range(currentLayerLen)])\n",
    "        self.biasVector = np.array([random.uniform(-1.0, 0.0) for i in range(currentLayerLen)])\n",
    "        #self.biasVector = np.zeros(currentLayerLen)\n",
    "        self.adjBiasVector = np.zeros(currentLayerLen)\n",
    "        self.zVector = np.zeros(shape = (currentLayerLen, 1))\n",
    "        self.errorVector = np.zeros(shape = (currentLayerLen, 1))\n",
    "        self.size = currentLayerLen\n",
    "\n",
    "    def resetLayer(self):\n",
    "        self.zVector = np.zeros(self.zVector.size)\n",
    "        self.errorVector = np.zeros(self.errorVector.size)\n",
    "\n",
    "    def resetAdjBiasVector(self):\n",
    "        self.adjBiasVector = np.zeros(self.biasVector.size)\n",
    "\n",
    "    def cout(self):\n",
    "        print(\"Activations: \")\n",
    "        print(self.activationVector)\n",
    "        print(\"Biases: \")\n",
    "        print(self.biasVector)\n",
    "        print(\"Z Vector: \")\n",
    "        print(self.zVector)\n",
    "        print(\"Error: \")\n",
    "        print(self.errorVector)\n",
    "\n",
    "    def coutBase(self):\n",
    "        print(\"Activations: \")\n",
    "        print(self.activationVector)\n",
    "        print(\"Biases: \")\n",
    "        print(self.biasVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weightMatrix:\n",
    "    def __init__(self, prevLayerLen, nextLayerLen):\n",
    "        self.matrix = np.random.rand(nextLayerLen, prevLayerLen) * 0.001\n",
    "        self.adjMatrix = np.zeros((nextLayerLen, prevLayerLen))\n",
    "\n",
    "    def resetAdjMatrix(self):\n",
    "        self.adjMatrix = np.zeros((self.matrix.shape))\n",
    "\n",
    "    def cout(self):\n",
    "        print(self.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # print(\"Sigmoid called with x = \", str(x))\n",
    "    if x <= -700:\n",
    "        x = -700\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoidDeriv(x):\n",
    "    # print(\"Sigmoid deriv called with x = \", str(x))\n",
    "    if x <= -350:\n",
    "        x = -350\n",
    "    return np.exp(-x) / ((1 + np.exp(-x)) * (1 + np.exp(-x)))\n",
    "\n",
    "class Network:\n",
    "\n",
    "    def __init__(self, start, first, second, end):\n",
    "        startLayer = Layer(start)\n",
    "        firstLayer = Layer(first)\n",
    "        secondLayer = Layer(second)\n",
    "        endLayer = Layer(end)\n",
    "\n",
    "        self.Layers = np.array([startLayer, firstLayer, secondLayer, endLayer])\n",
    "\n",
    "        firstMatrix = weightMatrix(start, first)\n",
    "        secondMatrix = weightMatrix(first, second)\n",
    "        endMatrix = weightMatrix(second, end)\n",
    "\n",
    "        # Indexed with the layer before the matrix\n",
    "        self.Matrices = np.array([firstMatrix, secondMatrix, endMatrix])\n",
    "\n",
    "    def calculateZVector(self, layerIdx):\n",
    "        # self.Layers[layerIdx - 1] is previous Layer\n",
    "        # currLayer = self.Layers[layerIdx] is current Layer\n",
    "        # self.Matrices[layerIdx - 1].matrix is weight matrix related to this calculation\n",
    "        # self.Layers[layerIdx - 1].activationVector is previous activation\n",
    "        # self.Layers[layerIdx].biasVector is current Bias\n",
    "\n",
    "        # Weight matrix * previous activation vector\n",
    "        self.Layers[layerIdx].zVector = np.dot(self.Matrices[layerIdx - 1].matrix, self.Layers[layerIdx - 1].activationVector)\n",
    "        # += current bias vector\n",
    "        self.Layers[layerIdx].zVector += self.Layers[layerIdx].biasVector\n",
    "\n",
    "    def forwardPropagationStep(self, layerIdx):\n",
    "        # currLayer = self.Layers[layerIdx] is current Layer\n",
    "\n",
    "        self.calculateZVector(layerIdx)\n",
    "\n",
    "        for i in range(self.Layers[layerIdx].size):\n",
    "            self.Layers[layerIdx].activationVector[i] = sigmoid(self.Layers[layerIdx].zVector[i])\n",
    "\n",
    "    # Assumes that data is between 0 and 255 value\n",
    "    def setStartLayerActivations(self, dataset):\n",
    "        # # FOR 4 3 3 2 test\n",
    "\n",
    "        # for idx in range(0, 4):\n",
    "        #     self.Layers[0].activationVector[idx] = dataset[idx]\n",
    "\n",
    "        #\n",
    "        # FOR MINST\n",
    "        #\n",
    "\n",
    "        # self.Layers[0] is start Layer\n",
    "\n",
    "        if len(dataset) * len(dataset[0]) != self.Layers[0].size:\n",
    "            print(\"There is a mismatch between the size of the input data and the start layer!\")\n",
    "            print(\"Size of dataset is: \" + str(len(dataset) * len(dataset[0])))\n",
    "            print(\"Size of first layer is: \" + str(self.Layers[0].size))\n",
    "\n",
    "        #print(\"1) Set the activations of the first layer\")\n",
    "\n",
    "        layerIdx = 0\n",
    "        for row in range(0, len(dataset)):\n",
    "            for col in range(0, len(dataset[0])):\n",
    "                self.Layers[0].activationVector[layerIdx] = dataset[row][col] / 255\n",
    "                layerIdx += 1\n",
    "\n",
    "    def fullForwardPropagation(self, target):\n",
    "        #print(\"2) Feedforward: Compute all activations for all layers\")\n",
    "        self.forwardPropagationStep(1)\n",
    "        self.forwardPropagationStep(2)\n",
    "        self.forwardPropagationStep(3)\n",
    "\n",
    "        #print(\"Target is: \" + str(target))\n",
    "        #print(\"Cost is: \" + str(self.cost(target)))\n",
    "    \n",
    "    def cost(self, target):\n",
    "        # self.Layers[self.Layers.size - 1] is end Layer\n",
    "\n",
    "        sum = 0\n",
    "\n",
    "        for i in range(self.Layers[self.Layers.size - 1].size):\n",
    "            if (i == target):\n",
    "                sum += (1.0 - self.Layers[self.Layers.size - 1].activationVector[i]) * (1.0 - self.Layers[self.Layers.size - 1].activationVector[i])\n",
    "            else:\n",
    "                sum += (self.Layers[self.Layers.size - 1].activationVector[i]) * (self.Layers[self.Layers.size - 1].activationVector[i])\n",
    "        return sum / (self.Layers[self.Layers.size - 1].size)\n",
    "    \n",
    "    def fullBackwardPropagation(self, target):\n",
    "        #print(\"3) Output Error in last layer\")\n",
    "        self.calculateErrorInLastLayerForTarget(target)\n",
    "\n",
    "        #print(\"4) Backpropagate error: calculate error for all layers\")\n",
    "        self.calculateErrorFromNextLayerError(2)\n",
    "        self.calculateErrorFromNextLayerError(1)\n",
    "    \n",
    "    # The cost function is hard coded\n",
    "    def calculateErrorInLastLayerForTarget(self, target):\n",
    "        # self.Layers[self.Layers.size - 1] is end Layer\n",
    "\n",
    "        # The desired value for target is 1\n",
    "        CGradient = np.zeros(self.Layers[self.Layers.size - 1].size)\n",
    "        for i in range(self.Layers[self.Layers.size - 1].size):\n",
    "            CGradient[i] = self.Layers[self.Layers.size - 1].activationVector[i]\n",
    "            if i == target:\n",
    "                CGradient[i] -= 1.0\n",
    "\n",
    "        # Apply sigmoid' to endLayer.zVector in place\n",
    "        for i in range(self.Layers[self.Layers.size - 1].size):\n",
    "            self.Layers[self.Layers.size - 1].zVector[i] = sigmoidDeriv(self.Layers[self.Layers.size - 1].zVector[i])\n",
    "\n",
    "        # sigmoid' was applied to endLayer.zVector in place\n",
    "        self.Layers[self.Layers.size - 1].errorVector = np.multiply(CGradient, self.Layers[self.Layers.size - 1].zVector)\n",
    "\n",
    "    # Assumes error in next layer is up to date\n",
    "    def calculateErrorFromNextLayerError(self, layerIdx):\n",
    "        # self.Layers[layerIdx] is current Layer\n",
    "        # self.Layers[layerIdx + 1] is next Layer\n",
    "\n",
    "        # self.Matrices[layerIdx].matrix.transpose() is the transposed weight matrix\n",
    "        # np.dot(transposedWeightMatrix, self.Layers[layerIdx + 1].errorVector) is transposed weight matrix * next layer error\n",
    "\n",
    "        # Apply sigmoid' to currLayer.zVector in place\n",
    "        for i in range(self.Layers[layerIdx].size):\n",
    "            self.Layers[layerIdx].zVector[i] = sigmoidDeriv(self.Layers[layerIdx].zVector[i])\n",
    "\n",
    "        # sigmoid' was applied to self.Layers[self.Layers.size - 1].zVector in place\n",
    "        # error = (transposed weight matrix * next layer error) o sigmoid'(z)\n",
    "        # Where o is index by index multiplication\n",
    "        self.Layers[layerIdx].errorVector = np.multiply(np.dot(self.Matrices[layerIdx].matrix.transpose(), self.Layers[layerIdx + 1].errorVector), self.Layers[layerIdx].zVector)\n",
    "\n",
    "    # All of this would be MUCH easier if W and B were stored as matrices and vectors\n",
    "    def adjustBasedOnGradientDescentForCurrentExample(self, learningRate, numberInBatch):\n",
    "        #print(\"5) Gradient Descent\")\n",
    "\n",
    "        # npm stands for n per m\n",
    "        # where: n: learning rate\n",
    "        #        m: number of train examples in batch\n",
    "        npm = learningRate / numberInBatch\n",
    "\n",
    "        # Adjust biases\n",
    "        for layerIdx in range(1, self.Layers.size):\n",
    "            # self.Layers[layerIdx] is current Layer\n",
    "\n",
    "            #self.Layers[layerIdx].biasVector -= npm * self.Layers[layerIdx].errorVector\n",
    "            #print(\"Delta is (bias): \", -npm * self.Layers[layerIdx].errorVector)\n",
    "\n",
    "            self.Layers[layerIdx].adjBiasVector += npm * self.Layers[layerIdx].errorVector\n",
    "\n",
    "        # # Adjust weights\n",
    "        for weightMatrixIdx in range(self.Matrices.size):\n",
    "            # self.Matrices[weightMatrixIdx].matrix is current weight matrix\n",
    "            # self.Layers[weightMatrixIdx + 1] is current Layer\n",
    "            # self.Layers[weightMatrixIdx] is previous Layer\n",
    "\n",
    "            # For matrix mupltiplications the vectors need to be 2D\n",
    "            # This is how we make them 2D\n",
    "            # np.array([self.Layers[weightMatrixIdx].activationVector]) is previous activations\n",
    "            # np.array([self.Layers[weightMatrixIdx + 1].errorVector]) is current error\n",
    "            # Temp variable to make code more understandable\n",
    "            \n",
    "            # weight matrix -= (current Error)T * previous activation\n",
    "            #self.Matrices[weightMatrixIdx].matrix -= npm * np.dot(np.array([self.Layers[weightMatrixIdx + 1].errorVector]).transpose(), np.array([self.Layers[weightMatrixIdx].activationVector]))\n",
    "            #print(\"Delta is (weight): \", -npm * np.dot(np.array([self.Layers[weightMatrixIdx + 1].errorVector]).transpose(), np.array([self.Layers[weightMatrixIdx].activationVector])))\n",
    "\n",
    "            self.Matrices[weightMatrixIdx].adjMatrix += npm * np.dot(np.array([self.Layers[weightMatrixIdx + 1].errorVector]).transpose(), np.array([self.Layers[weightMatrixIdx].activationVector]))\n",
    "\n",
    "    def resetNetwork(self):\n",
    "        for layer in self.Layers:\n",
    "            layer.resetLayer()\n",
    "\n",
    "    def resetAdjs(self):\n",
    "        for layer in self.Layers:\n",
    "            layer.resetAdjBiasVector()\n",
    "\n",
    "        for matrix in self.Matrices:\n",
    "            matrix.resetAdjMatrix()\n",
    "\n",
    "    def adjustWithAdjustVariables(self):\n",
    "        for layerIdx in range(1, self.Layers.size):\n",
    "            self.Layers[layerIdx].biasVector -= self.Layers[layerIdx].adjBiasVector\n",
    "\n",
    "        for weightMatrixIdx in range(self.Matrices.size):\n",
    "            self.Matrices[weightMatrixIdx].matrix -= self.Matrices[weightMatrixIdx].adjMatrix\n",
    "\n",
    "    def trainBatch(self, data, labels, learningRate):\n",
    "        # Check if there is a length mismatch\n",
    "        if (len(data) != len(labels)):\n",
    "            print(\"There is a mismatch between the length of the data and lables\")\n",
    "            print(\"Length of data is: \" + str(data.size))\n",
    "            print(\"Length of labels are: \" + str(labels.size))\n",
    "        numberInBatch = len(data)\n",
    "\n",
    "        self.resetAdjs()\n",
    "\n",
    "        for idx in range(numberInBatch):\n",
    "            # Steps of one training \n",
    "            # self.cout()\n",
    "            # print(\"\\n\\nRESET NETWORK\\n\\n\")\n",
    "            self.resetNetwork()\n",
    "            # self.cout()\n",
    "            # print(\"\\n\\nSET START LAYER ACTIVATIONS\\n\\n\")\n",
    "            self.setStartLayerActivations(data[idx])\n",
    "            # self.cout()\n",
    "            # print(\"\\n\\nFULL FORWARD PROPAGATION\\n\\n\")\n",
    "            self.fullForwardPropagation(labels[idx])\n",
    "            # self.cout()\n",
    "            # print(\"\\n\\nFULL BACKWARD PROPAGATION\\n\\n\")\n",
    "            self.fullBackwardPropagation(labels[idx])\n",
    "            # self.cout()\n",
    "            # print(\"\\n\\nADJUST BASED ON GRADIENT DESCENT FOR CURRENT EXAMPLE\\n\\n\")\n",
    "            self.adjustBasedOnGradientDescentForCurrentExample(learningRate, numberInBatch)\n",
    "        #     self.cout()\n",
    "\n",
    "        # print(\"\\n\\nADJUST WITH ADJUST VARIABLES\\n\\n\")\n",
    "        self.adjustWithAdjustVariables()\n",
    "        # self.cout()\n",
    "\n",
    "    def findPrediction(self):\n",
    "        endLayerActivations = self.Layers[self.Layers.size - 1].activationVector\n",
    "\n",
    "        max = 0\n",
    "        maxIdx = 11\n",
    "\n",
    "        for idx in range(endLayerActivations.size):\n",
    "            if endLayerActivations[idx] > max:\n",
    "                max = endLayerActivations[idx]\n",
    "                maxIdx = idx\n",
    "\n",
    "        return maxIdx\n",
    "\n",
    "    def test(self, data, labels):\n",
    "        # Check if there is a length mismatch\n",
    "        if (len(data) != len(labels)):\n",
    "            print(\"There is a mismatch between the length of the data and lables\")\n",
    "            print(\"Length of data is: \" + str(data.size))\n",
    "            print(\"Length of labels are: \" + str(labels.size))\n",
    "\n",
    "        numberOfTest = len(data)\n",
    "        sumCost = 0\n",
    "        correct = 0\n",
    "\n",
    "        for idx in range(numberOfTest):\n",
    "            self.setStartLayerActivations(data[idx])\n",
    "            self.fullForwardPropagation(labels[idx])\n",
    "\n",
    "            sumCost += self.cost(labels[idx])\n",
    "\n",
    "            correctIdx = self.findPrediction()\n",
    "            if correctIdx == labels[idx]:\n",
    "                correct += 1\n",
    "\n",
    "        print(\"Average cost is: \", sumCost / numberOfTest)\n",
    "        print(\"Percentage of correct is: \", correct / numberOfTest)\n",
    "\n",
    "    def checkRandomExamples(self, data, labels):\n",
    "        numberOfData = len(data)\n",
    "\n",
    "        for num in range (0, 20):\n",
    "            randIdx = random.randint(0, numberOfData)\n",
    "            \n",
    "            self.setStartLayerActivations(data[randIdx])\n",
    "            self.fullForwardPropagation(labels[randIdx])\n",
    "\n",
    "            print(\"Label for the data is: \" + str(labels[randIdx]))\n",
    "            self.coutLastLayer()\n",
    "            print(\"The cost is: \" + str(self.cost(labels[randIdx])))\n",
    "\n",
    "    def coutLastLayer(self):\n",
    "        print(\"The last layer activations are: \")\n",
    "        print(self.Layers[self.Layers.size - 1].activationVector)\n",
    "\n",
    "    def coutActivation(self):\n",
    "        for idx in range(self.Layers.size):\n",
    "            print(\"Layer: \" + str(idx))\n",
    "            print(self.Layers[idx].activationVector)\n",
    "\n",
    "    def coutBase(self):\n",
    "        for i in range(self.Matrices.size):\n",
    "            print(\"Layer: \", i)\n",
    "            self.Layers[i].coutBase()\n",
    "            print()\n",
    "            self.Matrices[i].cout()\n",
    "            print()\n",
    "\n",
    "        print(\"Layer: \", self.Layers.size - 1)\n",
    "        self.Layers[self.Layers.size - 1].coutBase()\n",
    "\n",
    "    def cout(self):\n",
    "        for i in range(self.Matrices.size):\n",
    "            print(\"Layer: \", i)\n",
    "            self.Layers[i].cout()\n",
    "            print()\n",
    "            self.Matrices[i].cout()\n",
    "            print()\n",
    "\n",
    "        print(\"Layer: \", self.Layers.size - 1)\n",
    "        self.Layers[self.Layers.size - 1].cout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on batch data:\n",
      "Average cost is:  0.022013135477692753\n",
      "Percentage of correct is:  0.8673333333333333\n",
      "Testing on test data:\n",
      "Average cost is:  0.022153029917169127\n",
      "Percentage of correct is:  0.8625\n",
      "Testing on the batch\n",
      "The last layer activations are: \n",
      "[3.98568443e-05 1.39581559e-02 8.97363497e-01 2.41931409e-02\n",
      " 3.51893021e-05 2.19144110e-03 2.21098453e-02 2.09771325e-03\n",
      " 3.71109909e-02 2.81552634e-05]\n",
      "The last layer activations are: \n",
      "[2.83768214e-02 2.15138619e-03 3.40353777e-02 8.76093628e-01\n",
      " 2.39489370e-05 5.66627699e-02 8.22000317e-05 1.82887935e-02\n",
      " 6.64705029e-03 2.32075224e-04]\n",
      "The last layer activations are: \n",
      "[6.58047622e-05 1.22694346e-02 8.31382109e-01 3.26469794e-02\n",
      " 3.66754050e-05 2.12947430e-03 1.20813720e-02 2.77490056e-03\n",
      " 2.77601937e-02 3.02866981e-05]\n",
      "The last layer activations are: \n",
      "[5.05522260e-03 3.90213751e-03 1.14965286e-01 6.16747916e-01\n",
      " 2.62073278e-05 1.89860234e-02 2.76323736e-04 1.09269829e-02\n",
      " 1.14122191e-02 1.38034482e-04]\n",
      "The last layer activations are: \n",
      "[6.80833780e-04 6.73418657e-03 4.06828699e-01 2.24547240e-01\n",
      " 2.96528605e-05 6.08038770e-03 1.47639692e-03 5.67888689e-03\n",
      " 2.11658059e-02 6.95580543e-05]\n",
      "The last layer activations are: \n",
      "[5.21999442e-03 3.89559746e-03 1.02231438e-01 5.86366226e-01\n",
      " 2.58796833e-05 1.51656135e-02 2.44822016e-04 1.04425959e-02\n",
      " 1.83853033e-02 1.51424189e-04]\n",
      "The last layer activations are: \n",
      "[4.16234089e-04 7.71559803e-03 5.54766324e-01 1.62116296e-01\n",
      " 3.09108929e-05 5.55686178e-03 2.50897220e-03 4.82299379e-03\n",
      " 2.25159975e-02 5.80840467e-05]\n",
      "The last layer activations are: \n",
      "[1.64422851e-02 2.69039414e-03 4.44171835e-02 7.73279684e-01\n",
      " 2.07726634e-05 2.59612552e-02 1.05832142e-04 1.15987324e-02\n",
      " 2.27545998e-02 2.28889608e-04]\n",
      "The last layer activations are: \n",
      "[3.53615179e-04 8.52969495e-03 6.08103922e-01 1.41968915e-01\n",
      " 3.17116724e-05 4.47851915e-03 2.91594232e-03 4.62804891e-03\n",
      " 2.13464240e-02 5.38324755e-05]\n",
      "The last layer activations are: \n",
      "[2.18975864e-02 2.33011570e-03 3.43035288e-02 8.03926959e-01\n",
      " 1.91068294e-05 3.02871364e-02 8.21337042e-05 1.07867825e-02\n",
      " 2.95379781e-02 2.74841733e-04]\n",
      "The last layer activations are: \n",
      "[2.47281468e-04 1.04383687e-02 7.13740493e-01 1.12012226e-01\n",
      " 3.25487060e-05 3.26882010e-03 4.54722747e-03 4.08947447e-03\n",
      " 1.64437075e-02 4.11754271e-05]\n",
      "The last layer activations are: \n",
      "[1.92150492e-02 2.56735646e-03 3.23211020e-02 7.96218767e-01\n",
      " 1.70754013e-05 2.37929617e-02 7.76732791e-05 1.00672141e-02\n",
      " 3.41861872e-02 2.63614566e-04]\n",
      "The last layer activations are: \n",
      "[4.10564097e-04 9.53231597e-03 6.15200408e-01 1.46183962e-01\n",
      " 2.97933530e-05 4.11762122e-03 3.05368299e-03 4.49103796e-03\n",
      " 1.44296849e-02 4.73992557e-05]\n",
      "The last layer activations are: \n",
      "[1.64472912e-02 2.88271785e-03 3.42429889e-02 7.76948779e-01\n",
      " 1.60946559e-05 2.03770393e-02 7.31390886e-05 1.03297426e-02\n",
      " 3.59169087e-02 2.54538050e-04]\n",
      "The last layer activations are: \n",
      "[8.57651264e-04 7.52515651e-03 4.66211301e-01 2.29477983e-01\n",
      " 2.70593530e-05 7.19759938e-03 1.61091466e-03 5.60877393e-03\n",
      " 1.30906324e-02 6.13164189e-05]\n",
      "The last layer activations are: \n",
      "[2.07497743e-02 2.65652341e-03 3.63862850e-02 8.19203220e-01\n",
      " 1.59538925e-05 2.45887900e-02 6.88168815e-05 1.25175554e-02\n",
      " 2.96540191e-02 2.44045810e-04]\n",
      "The last layer activations are: \n",
      "[8.13405214e-04 7.46281456e-03 4.67818348e-01 2.09565461e-01\n",
      " 2.53483215e-05 7.46289543e-03 1.66680913e-03 5.50673967e-03\n",
      " 1.69878787e-02 6.01486680e-05]\n",
      "The last layer activations are: \n",
      "[1.98841378e-02 2.79066346e-03 3.60084307e-02 8.19617739e-01\n",
      " 1.61274176e-05 2.23236406e-02 7.35581778e-05 1.26927340e-02\n",
      " 3.22127978e-02 2.28456786e-04]\n",
      "The last layer activations are: \n",
      "[1.15841371e-03 6.55644250e-03 3.98246305e-01 2.72734233e-01\n",
      " 2.41745508e-05 1.02945838e-02 1.12735555e-03 6.17330148e-03\n",
      " 1.69775963e-02 7.63273391e-05]\n",
      "The last layer activations are: \n",
      "[1.83580751e-02 2.92841829e-03 3.79770847e-02 8.06899506e-01\n",
      " 1.63535288e-05 2.07775357e-02 8.12075382e-05 1.20600484e-02\n",
      " 3.20666912e-02 2.19548091e-04]\n",
      "The last layer activations are: \n",
      "[3.93204930e-03 4.78954262e-03 1.51515212e-01 5.21580528e-01\n",
      " 2.16447856e-05 1.38101856e-02 2.97628416e-04 9.35086278e-03\n",
      " 2.00385487e-02 1.38356925e-04]\n",
      "The last layer activations are: \n",
      "[1.16546398e-02 3.47392423e-03 5.02432056e-02 7.44369753e-01\n",
      " 1.63343311e-05 1.51074879e-02 1.08664555e-04 1.04632163e-02\n",
      " 3.92094989e-02 1.93214171e-04]\n",
      "The last layer activations are: \n",
      "[1.22181391e-02 3.39083391e-03 7.20183063e-02 7.51361689e-01\n",
      " 1.94240102e-05 2.62130726e-02 1.28171680e-04 1.23797918e-02\n",
      " 1.68123535e-02 1.97738633e-04]\n",
      "The last layer activations are: \n",
      "[6.25243123e-03 4.12366184e-03 9.07608712e-02 6.31405898e-01\n",
      " 1.71798174e-05 1.24345920e-02 1.89448562e-04 8.61176069e-03\n",
      " 3.72227459e-02 1.62306332e-04]\n",
      "The last layer activations are: \n",
      "[2.18306649e-02 2.81666350e-03 4.60265651e-02 8.41868105e-01\n",
      " 1.85104020e-05 3.18766623e-02 8.08630215e-05 1.48509703e-02\n",
      " 1.70230023e-02 2.27287275e-04]\n",
      "The last layer activations are: \n",
      "[4.27858691e-03 4.40496992e-03 1.51625133e-01 5.42718093e-01\n",
      " 1.73424239e-05 1.34121135e-02 2.95628898e-04 7.43046754e-03\n",
      " 3.39589270e-02 1.42048875e-04]\n",
      "The last layer activations are: \n",
      "[2.12681249e-02 3.00428045e-03 4.77530398e-02 8.50629729e-01\n",
      " 1.83196464e-05 2.71863212e-02 8.08972327e-05 1.56764557e-02\n",
      " 1.58295960e-02 2.08026139e-04]\n",
      "The last layer activations are: \n",
      "[8.79951182e-03 3.65041089e-03 8.00756314e-02 6.69955983e-01\n",
      " 1.60652924e-05 1.79377198e-02 1.48153816e-04 8.51428236e-03\n",
      " 3.64937030e-02 1.92201600e-04]\n",
      "The last layer activations are: \n",
      "[1.14207186e-02 3.92943173e-03 7.41065189e-02 7.95330576e-01\n",
      " 1.98328839e-05 1.44407583e-02 1.12787640e-04 1.50998065e-02\n",
      " 1.47342735e-02 1.67810546e-04]\n",
      "The last layer activations are: \n",
      "[8.57923087e-03 3.82379257e-03 6.64772318e-02 6.26047854e-01\n",
      " 1.53818310e-05 1.49947323e-02 1.26308195e-04 8.29608881e-03\n",
      " 4.52225898e-02 2.06616648e-04]\n",
      "The last layer activations are: \n",
      "[8.22448869e-03 4.27577606e-03 1.03518793e-01 7.34779833e-01\n",
      " 2.04504642e-05 1.25496343e-02 1.63878601e-04 1.35279137e-02\n",
      " 1.35871859e-02 1.33542907e-04]\n",
      "The last layer activations are: \n",
      "[1.71031528e-02 3.02079172e-03 4.28979724e-02 7.71234466e-01\n",
      " 1.53166376e-05 2.34810311e-02 7.52548613e-05 1.15016119e-02\n",
      " 3.63099305e-02 2.38591091e-04]\n",
      "The last layer activations are: \n",
      "[4.60756984e-03 5.03752260e-03 1.48775900e-01 6.13008818e-01\n",
      " 1.97557312e-05 9.79892393e-03 2.66039708e-04 1.05015575e-02\n",
      " 1.89786876e-02 1.12381810e-04]\n",
      "The last layer activations are: \n",
      "[2.35962305e-02 2.68920126e-03 3.57126291e-02 8.27340057e-01\n",
      " 1.52193770e-05 3.24100749e-02 6.24036522e-05 1.27704344e-02\n",
      " 3.26519643e-02 2.68489588e-04]\n",
      "The last layer activations are: \n",
      "[2.65120217e-04 1.04139764e-02 6.78975970e-01 1.13965694e-01\n",
      " 2.41569087e-05 3.15843219e-03 3.57865072e-03 3.95829654e-03\n",
      " 2.89908397e-02 4.22249083e-05]\n",
      "The last layer activations are: \n",
      "[2.84623173e-02 2.48755842e-03 3.07036682e-02 8.67320073e-01\n",
      " 1.58710588e-05 3.94174326e-02 5.83196986e-05 1.42723083e-02\n",
      " 2.82837443e-02 2.64898569e-04]\n",
      "The last layer activations are: \n",
      "[5.09563659e-05 1.62235556e-02 8.82159528e-01 2.60279932e-02\n",
      " 2.52040315e-05 1.49769161e-03 1.46386857e-02 2.21419073e-03\n",
      " 4.41188109e-02 2.50791309e-05]\n",
      "The last layer activations are: \n",
      "[2.92497602e-02 2.45141398e-03 2.79640566e-02 8.81841065e-01\n",
      " 1.57121164e-05 4.90233770e-02 5.94087984e-05 1.46922523e-02\n",
      " 2.24059340e-02 2.66379510e-04]\n",
      "The last layer activations are: \n",
      "[6.25122600e-05 1.48561064e-02 8.26188412e-01 2.87139561e-02\n",
      " 2.36102119e-05 1.44810338e-03 1.14893830e-02 2.18313543e-03\n",
      " 5.62886555e-02 2.91850394e-05]\n",
      "The last layer activations are: \n",
      "[2.79141947e-02 2.36698031e-03 3.35445498e-02 8.66639370e-01\n",
      " 1.63782720e-05 5.54030279e-02 6.46308900e-05 1.39441372e-02\n",
      " 1.83885026e-02 2.82503469e-04]\n",
      "The last layer activations are: \n",
      "[1.51625135e-03 7.11311709e-03 1.70236968e-01 3.03502097e-01\n",
      " 1.57359979e-05 3.12065191e-03 4.48300494e-04 5.52858486e-03\n",
      " 7.26872640e-02 9.55348240e-05]\n",
      "The last layer activations are: \n",
      "[2.50295590e-02 2.53338418e-03 3.86937985e-02 8.53795310e-01\n",
      " 1.57818566e-05 4.39734171e-02 6.65436736e-05 1.34958366e-02\n",
      " 2.10148039e-02 2.63351956e-04]\n",
      "The last layer activations are: \n",
      "[4.71691199e-03 5.12869033e-03 8.72096859e-02 5.54501225e-01\n",
      " 1.51360625e-05 7.24309144e-03 1.71625292e-04 8.41847503e-03\n",
      " 4.89984426e-02 1.42883329e-04]\n",
      "The last layer activations are: \n",
      "[2.36801180e-02 2.63438443e-03 3.64925780e-02 8.38693444e-01\n",
      " 1.46893248e-05 3.37371855e-02 6.19171033e-05 1.28521055e-02\n",
      " 3.16392990e-02 2.50728107e-04]\n",
      "The last layer activations are: \n",
      "[6.78529322e-03 4.62477963e-03 6.96059703e-02 6.28947074e-01\n",
      " 1.50693327e-05 1.01727027e-02 1.23771797e-04 9.55242869e-03\n",
      " 4.45774326e-02 1.61236569e-04]\n",
      "The last layer activations are: \n",
      "[2.28773404e-02 2.69705068e-03 3.71358412e-02 8.37227625e-01\n",
      " 1.41616394e-05 3.20025660e-02 6.07194477e-05 1.24703897e-02\n",
      " 3.49863380e-02 2.46575339e-04]\n",
      "The last layer activations are: \n",
      "[7.88286474e-03 4.55225562e-03 6.03304911e-02 6.74224365e-01\n",
      " 1.52402097e-05 1.04945287e-02 1.02915474e-04 1.05624623e-02\n",
      " 4.21976798e-02 1.65761158e-04]\n",
      "The last layer activations are: \n",
      "[2.18119671e-02 2.70654748e-03 3.72538987e-02 8.32008037e-01\n",
      " 1.37064629e-05 2.93947709e-02 5.86261170e-05 1.21851862e-02\n",
      " 4.10345131e-02 2.51080017e-04]\n",
      "The last layer activations are: \n",
      "[9.25797810e-03 4.45206314e-03 6.25280358e-02 7.05792640e-01\n",
      " 1.58499796e-05 1.33045218e-02 1.05634336e-04 1.15180681e-02\n",
      " 3.02310123e-02 1.61919078e-04]\n",
      "The last layer activations are: \n",
      "[1.94494759e-02 2.84803460e-03 3.49142774e-02 8.19883612e-01\n",
      " 1.28444747e-05 2.16429315e-02 5.39640864e-05 1.16014982e-02\n",
      " 5.77035191e-02 2.45554575e-04]\n",
      "The last layer activations are: \n",
      "[1.18148818e-02 4.33790569e-03 7.16086665e-02 7.69511577e-01\n",
      " 1.68068472e-05 2.22252487e-02 1.07325793e-04 1.38697383e-02\n",
      " 1.32689608e-02 1.59763169e-04]\n",
      "The last layer activations are: \n",
      "[1.55541705e-02 3.23204466e-03 3.77429538e-02 7.88610966e-01\n",
      " 1.22302190e-05 1.73156719e-02 5.73421859e-05 1.08122887e-02\n",
      " 5.54121171e-02 2.41546111e-04]\n",
      "The last layer activations are: \n",
      "[1.12079894e-02 4.54564325e-03 7.90221467e-02 7.89421491e-01\n",
      " 1.75805030e-05 1.96781174e-02 1.19107253e-04 1.55268518e-02\n",
      " 9.50111733e-03 1.34867762e-04]\n",
      "The last layer activations are: \n",
      "[1.41194690e-02 3.48409314e-03 4.45949852e-02 7.91777976e-01\n",
      " 1.18313722e-05 1.76241523e-02 6.40107647e-05 1.20402729e-02\n",
      " 4.27258688e-02 2.16073240e-04]\n",
      "The last layer activations are: \n",
      "[6.57606246e-03 5.37785222e-03 1.05072683e-01 7.04267258e-01\n",
      " 1.74760556e-05 1.10464473e-02 1.73273962e-04 1.44651319e-02\n",
      " 1.19762789e-02 1.03837662e-04]\n",
      "The last layer activations are: \n",
      "[2.34418394e-02 2.73297069e-03 4.07797073e-02 8.48433264e-01\n",
      " 1.28919237e-05 3.30680218e-02 5.41287609e-05 1.45356195e-02\n",
      " 2.94608885e-02 2.31148437e-04]\n",
      "The last layer activations are: \n",
      "[6.33119178e-04 9.03134923e-03 4.70954069e-01 2.42727952e-01\n",
      " 1.85462262e-05 3.31984404e-03 1.37108770e-03 6.04118785e-03\n",
      " 2.55253690e-02 4.33420791e-05]\n",
      "The last layer activations are: \n",
      "[2.47090392e-02 2.67870209e-03 3.19478059e-02 8.66443625e-01\n",
      " 1.35999957e-05 3.79778613e-02 5.42070334e-05 1.41980199e-02\n",
      " 2.87148822e-02 2.34840273e-04]\n",
      "The last layer activations are: \n",
      "[9.48887949e-05 1.31531698e-02 8.10317977e-01 5.63634771e-02\n",
      " 2.11290662e-05 1.38653588e-03 7.57930209e-03 3.04210296e-03\n",
      " 4.07842814e-02 2.40772185e-05]\n",
      "The last layer activations are: \n",
      "[2.52787645e-02 2.71930302e-03 2.77486443e-02 8.70227725e-01\n",
      " 1.37436505e-05 3.39833138e-02 5.19415457e-05 1.51511156e-02\n",
      " 2.91424597e-02 2.20920701e-04]\n",
      "The last layer activations are: \n",
      "[2.00916842e-04 1.02615761e-02 6.47021322e-01 8.71308911e-02\n",
      " 1.92461754e-05 2.40982013e-03 3.48594196e-03 3.43516631e-03\n",
      " 4.88115629e-02 3.74231749e-05]\n",
      "The last layer activations are: \n",
      "[2.39263177e-02 2.68678893e-03 3.07919639e-02 8.55013181e-01\n",
      " 1.39126892e-05 3.58101497e-02 5.40692952e-05 1.47934249e-02\n",
      " 2.72154706e-02 2.32888377e-04]\n",
      "The last layer activations are: \n",
      "[1.08410898e-03 6.62016089e-03 2.87499810e-01 2.68029730e-01\n",
      " 1.63141068e-05 5.44815447e-03 7.24460891e-04 5.10212379e-03\n",
      " 5.07657291e-02 6.90701962e-05]\n",
      "The last layer activations are: \n",
      "[2.36148357e-02 2.67373636e-03 3.26983965e-02 8.56280401e-01\n",
      " 1.45492076e-05 3.55263595e-02 5.34087611e-05 1.44458565e-02\n",
      " 2.61225700e-02 2.26114842e-04]\n",
      "The last layer activations are: \n",
      "[1.12561685e-02 3.60038146e-03 4.37713040e-02 7.35818339e-01\n",
      " 1.20295820e-05 1.19096509e-02 7.78244781e-05 9.35533704e-03\n",
      " 6.66200370e-02 1.63567177e-04]\n",
      "The last layer activations are: \n",
      "[2.09813788e-02 3.04106288e-03 3.73208945e-02 8.52168314e-01\n",
      " 1.46155219e-05 2.96254893e-02 5.27552267e-05 1.51569479e-02\n",
      " 2.06075124e-02 2.10744592e-04]\n",
      "The last layer activations are: \n",
      "[1.69836895e-02 2.96102501e-03 3.24053320e-02 7.91832221e-01\n",
      " 1.17773656e-05 1.61705174e-02 5.29488024e-05 9.67766494e-03\n",
      " 6.76374985e-02 2.10453332e-04]\n",
      "The last layer activations are: \n",
      "[1.97456824e-02 3.29548892e-03 4.50964179e-02 8.52656052e-01\n",
      " 1.43046381e-05 2.84472436e-02 5.94299248e-05 1.41726743e-02\n",
      " 1.55010806e-02 1.79524209e-04]\n",
      "The last layer activations are: \n",
      "[1.19124075e-02 3.43664006e-03 3.62018666e-02 7.16588897e-01\n",
      " 1.16149143e-05 1.12662267e-02 5.67852812e-05 8.50138148e-03\n",
      " 7.79860820e-02 2.08061534e-04]\n",
      "The last layer activations are: \n",
      "[1.99397229e-02 3.20181170e-03 4.88925392e-02 8.67113190e-01\n",
      " 1.41767568e-05 2.52177770e-02 6.23185562e-05 1.45839355e-02\n",
      " 1.49262277e-02 1.67153566e-04]\n",
      "The last layer activations are: \n",
      "[1.33707664e-02 3.25072264e-03 4.28880792e-02 7.52550895e-01\n",
      " 1.18527200e-05 1.51000675e-02 5.97737798e-05 9.90194626e-03\n",
      " 5.36671892e-02 2.00872781e-04]\n",
      "The last layer activations are: \n",
      "[2.01257494e-02 3.08880436e-03 4.36578502e-02 8.59368803e-01\n",
      " 1.41949746e-05 2.26826652e-02 6.34064290e-05 1.47883916e-02\n",
      " 1.97017054e-02 1.52999804e-04]\n",
      "The last layer activations are: \n",
      "[1.29559291e-02 3.33076961e-03 4.32923390e-02 7.59283228e-01\n",
      " 1.23351985e-05 1.38318715e-02 6.13976854e-05 1.09772918e-02\n",
      " 5.51176990e-02 1.71297158e-04]\n",
      "The last layer activations are: \n",
      "[2.17675492e-02 2.87798306e-03 4.07961362e-02 8.57348538e-01\n",
      " 1.37141575e-05 2.88752706e-02 5.89753183e-05 1.40069525e-02\n",
      " 2.33066019e-02 1.77158212e-04]\n",
      "The last layer activations are: \n",
      "[1.04561437e-02 3.73714797e-03 3.96751626e-02 7.25965429e-01\n",
      " 1.12584043e-05 9.95560874e-03 5.82070620e-05 9.98139630e-03\n",
      " 7.38838921e-02 1.77056058e-04]\n",
      "The last layer activations are: \n",
      "[2.17342134e-02 2.81963591e-03 4.09502761e-02 8.61819768e-01\n",
      " 1.35316866e-05 3.12241462e-02 6.13777500e-05 1.39372881e-02\n",
      " 2.23129415e-02 1.75575283e-04]\n",
      "The last layer activations are: \n",
      "[6.91070843e-03 4.27025653e-03 4.61144591e-02 6.59423210e-01\n",
      " 1.19962144e-05 7.12632383e-03 7.51031298e-05 8.83305111e-03\n",
      " 8.42376849e-02 1.52244619e-04]\n",
      "The last layer activations are: \n",
      "[2.35908145e-02 2.54747742e-03 4.01105615e-02 8.77880999e-01\n",
      " 1.36864997e-05 3.54400063e-02 5.62754180e-05 1.40263076e-02\n",
      " 2.45197675e-02 1.89887719e-04]\n",
      "The last layer activations are: \n",
      "[7.05091843e-03 4.12520984e-03 5.49289094e-02 6.66380166e-01\n",
      " 1.20245906e-05 8.60950992e-03 8.61624338e-05 8.75523178e-03\n",
      " 6.93283272e-02 1.46196341e-04]\n",
      "The last layer activations are: \n",
      "[2.32585009e-02 2.49505871e-03 3.76421163e-02 8.73667945e-01\n",
      " 1.34741206e-05 3.68839113e-02 5.23276364e-05 1.34659871e-02\n",
      " 2.62617300e-02 2.05932866e-04]\n",
      "The last layer activations are: \n",
      "[9.58032674e-04 5.93231187e-03 3.65659399e-01 2.77155309e-01\n",
      " 1.62352044e-05 5.93532778e-03 7.88777368e-04 4.99308869e-03\n",
      " 4.02503920e-02 6.35207023e-05]\n",
      "The last layer activations are: \n",
      "[2.35025935e-02 2.46758479e-03 3.38417188e-02 8.74886675e-01\n",
      " 1.35146885e-05 3.99439948e-02 4.89474774e-05 1.34728948e-02\n",
      " 2.44028420e-02 2.19403737e-04]\n",
      "The last layer activations are: \n",
      "[6.71744614e-05 1.00298433e-02 8.77800870e-01 3.82422531e-02\n",
      " 2.31856368e-05 2.31675626e-03 1.03652983e-02 2.27348924e-03\n",
      " 3.44624327e-02 2.39099089e-05]\n",
      "The last layer activations are: \n",
      "[2.34312176e-02 2.54576506e-03 3.20937187e-02 8.77255343e-01\n",
      " 1.36646920e-05 4.56910555e-02 4.38608066e-05 1.39968134e-02\n",
      " 1.90083955e-02 2.35004892e-04]\n",
      "The last layer activations are: \n",
      "[4.92093301e-05 1.02316688e-02 9.11875334e-01 2.99657546e-02\n",
      " 2.57077587e-05 2.02151504e-03 1.59726072e-02 1.99727505e-03\n",
      " 3.21000499e-02 1.92802451e-05]\n",
      "The last layer activations are: \n",
      "[2.36952890e-02 2.75701324e-03 2.92800796e-02 8.84370176e-01\n",
      " 1.39885530e-05 4.95166887e-02 4.25042011e-05 1.34515517e-02\n",
      " 1.51568340e-02 2.23011705e-04]\n",
      "The last layer activations are: \n",
      "[4.11132196e-05 1.03567647e-02 9.23862652e-01 2.53149944e-02\n",
      " 2.58557700e-05 1.88001280e-03 1.78429778e-02 1.90210558e-03\n",
      " 3.10959037e-02 1.89725937e-05]\n",
      "The last layer activations are: \n",
      "[2.33828722e-02 2.94927977e-03 2.72043205e-02 8.83458958e-01\n",
      " 1.35011131e-05 5.75677104e-02 4.13416446e-05 1.29821757e-02\n",
      " 1.16111510e-02 2.32280384e-04]\n",
      "The last layer activations are: \n",
      "[5.99361635e-04 6.60045558e-03 2.96714649e-01 1.94327398e-01\n",
      " 1.50658022e-05 1.85284028e-03 7.63337336e-04 3.78392164e-03\n",
      " 9.90330944e-02 5.24665112e-05]\n",
      "The last layer activations are: \n",
      "[2.48261069e-02 2.56419791e-03 3.58039250e-02 8.82036448e-01\n",
      " 1.42108455e-05 6.04756387e-02 4.72209474e-05 1.25728167e-02\n",
      " 1.26515746e-02 2.21634642e-04]\n",
      "The last layer activations are: \n",
      "[4.85406633e-03 4.67102623e-03 5.09154767e-02 6.37290688e-01\n",
      " 1.12041849e-05 3.07875085e-03 8.27293416e-05 7.61843292e-03\n",
      " 1.04760523e-01 1.16866074e-04]\n",
      "The last layer activations are: \n",
      "[2.40331534e-02 2.29455661e-03 3.82483256e-02 8.71616827e-01\n",
      " 1.42191436e-05 5.61422230e-02 5.00117994e-05 1.07491691e-02\n",
      " 1.69650395e-02 2.48451367e-04]\n",
      "The last layer activations are: \n",
      "[5.21099421e-03 5.16037481e-03 4.39664337e-02 6.76664594e-01\n",
      " 1.12025021e-05 2.66682819e-03 6.22794937e-05 8.84659890e-03\n",
      " 8.82689437e-02 1.19147720e-04]\n",
      "The last layer activations are: \n",
      "[2.07526905e-02 2.34721475e-03 3.25412771e-02 8.22829655e-01\n",
      " 1.27869188e-05 3.16603128e-02 4.62172104e-05 8.93607286e-03\n",
      " 3.63219400e-02 2.41879428e-04]\n",
      "The last layer activations are: \n",
      "[6.88089784e-03 5.10193175e-03 4.88004872e-02 7.23367337e-01\n",
      " 1.18807155e-05 5.85125181e-03 5.89826431e-05 9.81660034e-03\n",
      " 3.63302078e-02 1.29824525e-04]\n",
      "The last layer activations are: \n",
      "[2.09648650e-02 2.25002854e-03 3.13532018e-02 8.10930866e-01\n",
      " 1.21418267e-05 2.72255879e-02 4.32098871e-05 8.76936052e-03\n",
      " 4.85725613e-02 2.32323482e-04]\n",
      "The last layer activations are: \n",
      "[8.78570693e-03 5.11795426e-03 5.14330232e-02 7.74079085e-01\n",
      " 1.18961266e-05 1.05152450e-02 5.70058331e-05 1.07761433e-02\n",
      " 1.72176788e-02 1.34255033e-04]\n",
      "The last layer activations are: \n",
      "[1.87269584e-02 2.26660204e-03 3.00670551e-02 7.97979876e-01\n",
      " 1.12007292e-05 2.41782249e-02 4.09790783e-05 8.22316167e-03\n",
      " 6.03106039e-02 2.38100451e-04]\n",
      "The last layer activations are: \n",
      "[7.44069158e-03 6.01215546e-03 5.53670522e-02 7.51131519e-01\n",
      " 1.34699165e-05 1.07038249e-02 5.63502347e-05 1.27050692e-02\n",
      " 9.57963218e-03 1.26494693e-04]\n",
      "The last layer activations are: \n",
      "[1.80610756e-02 2.40149591e-03 3.18530697e-02 8.03649521e-01\n",
      " 1.05393092e-05 2.04682970e-02 3.99124613e-05 9.52437014e-03\n",
      " 5.85988194e-02 2.02205515e-04]\n",
      "The last layer activations are: \n",
      "[1.04297081e-02 4.73505448e-03 5.62208009e-02 7.80109376e-01\n",
      " 1.24454074e-05 1.62549862e-02 6.71027587e-05 1.21618361e-02\n",
      " 9.79301246e-03 1.22364642e-04]\n",
      "The last layer activations are: \n",
      "[1.50204979e-02 2.87418745e-03 3.36278762e-02 7.92199032e-01\n",
      " 1.02071957e-05 1.35571496e-02 4.22656908e-05 1.07405494e-02\n",
      " 5.97011941e-02 1.65486256e-04]\n",
      "The last layer activations are: \n",
      "[1.56723636e-02 3.30484314e-03 4.65256877e-02 8.10088164e-01\n",
      " 1.11857248e-05 2.06489995e-02 6.02014227e-05 1.14193603e-02\n",
      " 2.15473809e-02 1.32840504e-04]\n",
      "The last layer activations are: \n",
      "[1.78997089e-02 2.92060605e-03 3.29377793e-02 8.12854109e-01\n",
      " 9.83194724e-06 1.78254986e-02 3.96763447e-05 1.10403614e-02\n",
      " 4.57139788e-02 1.73528263e-04]\n",
      "The last layer activations are: \n",
      "[1.06188859e-02 3.73956089e-03 4.06330566e-02 7.60300804e-01\n",
      " 1.05150438e-05 1.06245924e-02 5.59172662e-05 9.91675394e-03\n",
      " 4.60135618e-02 1.29746708e-04]\n",
      "The last layer activations are: \n",
      "[1.94482825e-02 2.53641626e-03 3.42317130e-02 8.42548560e-01\n",
      " 1.10878567e-05 2.63090110e-02 4.35212314e-05 1.12584959e-02\n",
      " 3.83337477e-02 1.79886898e-04]\n",
      "The last layer activations are: \n",
      "[1.02537332e-02 3.73753053e-03 3.49704995e-02 7.66151213e-01\n",
      " 1.02051865e-05 8.86841746e-03 4.51636774e-05 9.95491812e-03\n",
      " 6.02463354e-02 1.41888168e-04]\n",
      "The last layer activations are: \n",
      "[1.96573674e-02 2.42299080e-03 3.41056874e-02 8.47753351e-01\n",
      " 1.09552579e-05 2.69585503e-02 4.19709957e-05 1.13632734e-02\n",
      " 3.89587771e-02 1.84158691e-04]\n",
      "The last layer activations are: \n",
      "[9.34383621e-03 3.89879983e-03 3.55664669e-02 7.57583189e-01\n",
      " 1.03256682e-05 9.13639329e-03 4.52424876e-05 9.79648078e-03\n",
      " 5.43755860e-02 1.42606065e-04]\n",
      "The last layer activations are: \n",
      "[1.99829235e-02 2.27429003e-03 3.42728462e-02 8.59511860e-01\n",
      " 1.09429964e-05 2.95842484e-02 4.17114784e-05 1.15209536e-02\n",
      " 3.76736490e-02 1.86123767e-04]\n",
      "The last layer activations are: \n",
      "[8.13064358e-03 4.13448459e-03 3.71887891e-02 7.47433391e-01\n",
      " 1.04069933e-05 7.90989722e-03 4.68310057e-05 9.91507340e-03\n",
      " 5.20852669e-02 1.35679224e-04]\n",
      "The last layer activations are: \n",
      "[1.99739048e-02 2.17082468e-03 3.33170274e-02 8.61963762e-01\n",
      " 1.13962346e-05 3.27203037e-02 4.21710321e-05 1.09060486e-02\n",
      " 3.71725175e-02 1.92514534e-04]\n",
      "The last layer activations are: \n",
      "[7.61702071e-03 4.25273258e-03 3.99343497e-02 7.52115935e-01\n",
      " 1.04586855e-05 7.57383612e-03 4.72439425e-05 1.02459499e-02\n",
      " 4.70917001e-02 1.35056907e-04]\n",
      "The last layer activations are: \n",
      "[1.95434488e-02 2.11515424e-03 3.20402479e-02 8.52083154e-01\n",
      " 1.12217133e-05 3.70268403e-02 4.08867802e-05 9.57448662e-03\n",
      " 3.84759785e-02 2.19102643e-04]\n",
      "The last layer activations are: \n",
      "[6.48541995e-03 4.85846619e-03 4.33512619e-02 7.42992698e-01\n",
      " 1.11724806e-05 6.94659474e-03 4.73040140e-05 1.10950391e-02\n",
      " 3.22475344e-02 1.37540879e-04]\n",
      "The last layer activations are: \n",
      "[1.85972745e-02 2.06386272e-03 3.02682502e-02 8.46603746e-01\n",
      " 1.06891309e-05 3.20045122e-02 3.84269989e-05 9.07723382e-03\n",
      " 4.87113469e-02 2.26299396e-04]\n",
      "The last layer activations are: \n",
      "[5.36469125e-03 6.19515852e-03 4.62923774e-02 7.18829835e-01\n",
      " 1.25766383e-05 6.85457014e-03 4.62694407e-05 1.32458719e-02\n",
      " 1.55664374e-02 1.33465122e-04]\n",
      "The last layer activations are: \n",
      "[1.78301544e-02 2.16283106e-03 2.65181437e-02 8.33726468e-01\n",
      " 9.73043416e-06 1.74120369e-02 3.48952602e-05 9.79882870e-03\n",
      " 7.61503151e-02 1.84188316e-04]\n",
      "The last layer activations are: \n",
      "[6.85616008e-03 6.65113837e-03 5.23122460e-02 7.79747291e-01\n",
      " 1.05519506e-05 1.37397017e-02 5.29522564e-05 1.18000924e-02\n",
      " 7.11906989e-03 1.18799647e-04]\n",
      "The last layer activations are: \n",
      "[1.95666514e-02 2.17614000e-03 3.02086694e-02 8.59201175e-01\n",
      " 9.70791826e-06 2.29670510e-02 3.81652922e-05 1.13341744e-02\n",
      " 4.58672070e-02 1.84964950e-04]\n",
      "The last layer activations are: \n",
      "[9.19065403e-03 3.76690216e-03 7.20879231e-02 7.75823106e-01\n",
      " 1.16733111e-05 2.06009330e-02 9.67385262e-05 1.12712132e-02\n",
      " 1.08880777e-02 9.63933743e-05]\n",
      "The last layer activations are: \n",
      "[1.44214259e-02 3.04257652e-03 2.50353674e-02 8.17447142e-01\n",
      " 8.75247855e-06 1.14102702e-02 3.28489734e-05 1.06480804e-02\n",
      " 6.71827999e-02 1.52163432e-04]\n",
      "The last layer activations are: \n",
      "[2.04569004e-02 2.46216260e-03 5.78747155e-02 8.60169093e-01\n",
      " 1.11817522e-05 4.32974081e-02 7.37146326e-05 1.30343424e-02\n",
      " 1.08034426e-02 1.21416031e-04]\n",
      "The last layer activations are: \n",
      "[5.71933748e-03 4.67572895e-03 3.04753699e-02 6.62874088e-01\n",
      " 8.86239433e-06 3.78697710e-03 4.29613308e-05 8.59376454e-03\n",
      " 9.96029708e-02 1.25273123e-04]\n",
      "The last layer activations are: \n",
      "[2.83128536e-02 1.96329787e-03 4.65541244e-02 8.96640507e-01\n",
      " 1.11809643e-05 5.10178913e-02 5.76691964e-05 1.41241499e-02\n",
      " 1.47775664e-02 1.41324647e-04]\n",
      "The last layer activations are: \n",
      "[5.85563745e-03 4.68388469e-03 3.93086678e-02 6.70665937e-01\n",
      " 8.42508806e-06 4.60299196e-03 4.98875820e-05 8.26714819e-03\n",
      " 8.16630925e-02 1.16981247e-04]\n",
      "The last layer activations are: \n",
      "[2.55594712e-02 2.07123501e-03 4.03136782e-02 8.93614802e-01\n",
      " 1.08298046e-05 4.23481460e-02 5.22325111e-05 1.34519394e-02\n",
      " 1.93391020e-02 1.45966626e-04]\n",
      "The last layer activations are: \n",
      "[8.23970079e-03 4.07626702e-03 3.61154785e-02 7.43366357e-01\n",
      " 8.92575188e-06 7.28782630e-03 4.66607987e-05 9.22148741e-03\n",
      " 5.88731171e-02 1.19034128e-04]\n",
      "The last layer activations are: \n",
      "[2.05369513e-02 2.24797238e-03 3.66494541e-02 8.70244621e-01\n",
      " 1.02716145e-05 2.88565595e-02 4.38912822e-05 1.20726680e-02\n",
      " 3.06466493e-02 1.54189797e-04]\n",
      "The last layer activations are: \n",
      "[1.13247720e-02 3.32537366e-03 3.24085167e-02 8.07561252e-01\n",
      " 8.88036845e-06 1.01893439e-02 3.94055818e-05 1.03289402e-02\n",
      " 5.41739964e-02 1.29982454e-04]\n",
      "The last layer activations are: \n",
      "[1.72835242e-02 2.41525133e-03 3.26605330e-02 8.49215919e-01\n",
      " 9.75685618e-06 2.36626465e-02 3.95661094e-05 1.08601467e-02\n",
      " 3.83947530e-02 1.59714955e-04]\n",
      "The last layer activations are: \n",
      "[9.97108283e-03 3.29617310e-03 3.37369804e-02 8.03311994e-01\n",
      " 8.73224924e-06 8.30087150e-03 4.01891506e-05 1.00816691e-02\n",
      " 6.16138872e-02 1.21950831e-04]\n",
      "The last layer activations are: \n",
      "[1.83227121e-02 2.24082283e-03 3.22864016e-02 8.60696204e-01\n",
      " 1.00407948e-05 3.17777995e-02 3.85317813e-05 1.06657438e-02\n",
      " 3.15159442e-02 1.78319705e-04]\n",
      "The last layer activations are: \n",
      "[9.81358537e-03 3.15580412e-03 3.46087936e-02 8.06195053e-01\n",
      " 8.49790617e-06 7.49096519e-03 4.18258318e-05 9.76944010e-03\n",
      " 6.78718545e-02 1.14633645e-04]\n",
      "The last layer activations are: \n",
      "[1.81934835e-02 2.24342059e-03 3.14125569e-02 8.58898682e-01\n",
      " 1.01280793e-05 4.05741923e-02 3.76034723e-05 9.94349014e-03\n",
      " 2.60266553e-02 1.97477283e-04]\n",
      "The last layer activations are: \n",
      "[5.27740839e-03 3.62717145e-03 5.05544205e-02 7.15837288e-01\n",
      " 8.45945403e-06 4.02366230e-03 6.34719608e-05 7.91837010e-03\n",
      " 8.86819994e-02 8.71770290e-05]\n",
      "The last layer activations are: \n",
      "[1.57616041e-02 2.56326730e-03 2.75088956e-02 8.37751363e-01\n",
      " 9.69371835e-06 4.70538360e-02 3.49600088e-05 7.95146206e-03\n",
      " 2.23118460e-02 2.31975726e-04]\n",
      "The last layer activations are: \n",
      "[1.21326574e-03 4.66266195e-03 1.90167513e-01 4.07950626e-01\n",
      " 1.04544267e-05 2.42264817e-03 2.78513609e-04 5.06378108e-03\n",
      " 6.66668443e-02 4.94067211e-05]\n",
      "The last layer activations are: \n",
      "[1.92551570e-02 2.40766537e-03 2.67504624e-02 8.60982397e-01\n",
      " 9.47631610e-06 4.13754847e-02 3.48808782e-05 1.01082681e-02\n",
      " 2.22156906e-02 1.86157590e-04]\n",
      "The last layer activations are: \n",
      "[6.08591324e-05 6.87271624e-03 8.78050439e-01 4.18271122e-02\n",
      " 1.89327796e-05 2.07289877e-03 8.11830807e-03 2.16065028e-03\n",
      " 2.65186099e-02 1.86388826e-05]\n",
      "The last layer activations are: \n",
      "[2.09010508e-02 2.30626249e-03 2.62987220e-02 8.81791691e-01\n",
      " 9.42217233e-06 4.39510385e-02 3.52302897e-05 1.17027733e-02\n",
      " 2.07830737e-02 1.75426638e-04]\n",
      "The last layer activations are: \n",
      "[3.59155397e-05 7.12752150e-03 9.39853550e-01 2.53864921e-02\n",
      " 2.26060173e-05 2.70976644e-03 1.79600827e-02 1.86713946e-03\n",
      " 1.73039281e-02 1.50369350e-05]\n",
      "The last layer activations are: \n",
      "[1.98425698e-02 2.54072254e-03 2.24324436e-02 8.76790637e-01\n",
      " 9.69389240e-06 4.69688151e-02 3.34329782e-05 1.14922604e-02\n",
      " 1.85873178e-02 1.75174049e-04]\n",
      "The last layer activations are: \n",
      "[3.76793023e-05 6.50460293e-03 9.40206110e-01 2.55525114e-02\n",
      " 2.33259400e-05 3.24354668e-03 1.90870157e-02 1.92710122e-03\n",
      " 1.70322241e-02 1.56898210e-05]\n",
      "The last layer activations are: \n",
      "[1.74049320e-02 3.18710947e-03 1.93792875e-02 8.68091825e-01\n",
      " 9.36232660e-06 4.40852127e-02 3.06566283e-05 1.16228405e-02\n",
      " 1.35763010e-02 1.73697136e-04]\n",
      "The last layer activations are: \n",
      "[4.93918392e-03 2.49557901e-03 9.95218266e-02 6.52583078e-01\n",
      " 1.06059878e-05 1.16586030e-02 1.53126698e-04 7.74860307e-03\n",
      " 4.72706455e-02 7.68710016e-05]\n",
      "The last layer activations are: \n",
      "[1.08380942e-02 5.82890614e-03 2.06805831e-02 8.30083025e-01\n",
      " 9.15083086e-06 2.74496544e-02 2.33493825e-05 1.24022741e-02\n",
      " 6.60498705e-03 1.81621435e-04]\n",
      "The last layer activations are: \n",
      "[2.14220398e-02 1.67213737e-03 3.10098603e-02 8.70332283e-01\n",
      " 9.09566309e-06 2.43308782e-02 3.86312014e-05 1.15647192e-02\n",
      " 4.66703512e-02 1.37147426e-04]\n",
      "The last layer activations are: \n",
      "[1.47242249e-02 5.07049578e-03 2.56930787e-02 8.66741760e-01\n",
      " 7.28245561e-06 3.30917137e-02 3.10969655e-05 9.90097386e-03\n",
      " 7.88189367e-03 1.30060744e-04]\n",
      "The last layer activations are: \n",
      "[1.73313350e-02 2.29986213e-03 3.12240379e-02 8.45411811e-01\n",
      " 8.41536094e-06 1.87823463e-02 3.57922433e-05 1.09605058e-02\n",
      " 4.08340997e-02 1.32091656e-04]\n",
      "The last layer activations are: \n",
      "[2.02604173e-02 2.68935104e-03 3.07211902e-02 8.79349219e-01\n",
      " 8.53833376e-06 3.15436328e-02 3.64224066e-05 1.17979242e-02\n",
      " 1.77230382e-02 1.32190174e-04]\n",
      "The last layer activations are: \n",
      "[1.47497348e-02 2.90352104e-03 2.98122689e-02 8.31947812e-01\n",
      " 7.78628106e-06 1.59354857e-02 3.34603674e-05 1.02506453e-02\n",
      " 3.87966805e-02 1.24575629e-04]\n",
      "The last layer activations are: \n",
      "[2.02761675e-02 2.51697815e-03 3.21908657e-02 8.80565063e-01\n",
      " 8.36823137e-06 2.94299303e-02 3.55226938e-05 1.18048851e-02\n",
      " 2.18330796e-02 1.30827813e-04]\n",
      "The last layer activations are: \n",
      "[1.59518408e-02 2.68837504e-03 3.03429270e-02 8.42925576e-01\n",
      " 7.87387411e-06 2.00301221e-02 3.26677940e-05 1.03012100e-02\n",
      " 3.55526848e-02 1.32451832e-04]\n",
      "The last layer activations are: \n",
      "[1.74940016e-02 2.80768593e-03 3.22200690e-02 8.77112651e-01\n",
      " 7.81696626e-06 2.10416202e-02 3.37319899e-05 1.18501238e-02\n",
      " 2.40592530e-02 1.18684500e-04]\n",
      "The last layer activations are: \n",
      "[1.57356480e-02 2.67558267e-03 2.93385671e-02 8.41039189e-01\n",
      " 7.69930804e-06 2.24613694e-02 3.14657476e-05 9.36850104e-03\n",
      " 3.49439557e-02 1.40370373e-04]\n",
      "The last layer activations are: \n",
      "[1.68064589e-02 2.92975922e-03 3.20098528e-02 8.78362694e-01\n",
      " 7.67526407e-06 2.01535454e-02 3.26585953e-05 1.21201398e-02\n",
      " 2.18379371e-02 1.14293735e-04]\n",
      "The last layer activations are: \n",
      "[1.53701499e-02 2.54812820e-03 2.88713328e-02 8.37025912e-01\n",
      " 7.62423487e-06 2.36243607e-02 3.08997364e-05 8.71803430e-03\n",
      " 3.80102616e-02 1.46931440e-04]\n",
      "The last layer activations are: \n",
      "[1.68965184e-02 3.12943655e-03 3.35283375e-02 8.85780866e-01\n",
      " 7.70630552e-06 2.12374984e-02 3.19648772e-05 1.36519584e-02\n",
      " 1.48616072e-02 1.07649375e-04]\n",
      "The last layer activations are: \n",
      "[1.38583246e-02 2.69191811e-03 2.51432375e-02 7.94582567e-01\n",
      " 7.13397386e-06 1.53461012e-02 2.70077194e-05 8.30179601e-03\n",
      " 5.78669200e-02 1.41428115e-04]\n",
      "The last layer activations are: \n",
      "[1.63395896e-02 3.44800184e-03 3.80120163e-02 8.94710325e-01\n",
      " 7.23328609e-06 2.36421390e-02 3.37224101e-05 1.36077049e-02\n",
      " 9.23693365e-03 1.00372798e-04]\n",
      "The last layer activations are: \n",
      "[1.57388767e-02 2.46218767e-03 3.11795282e-02 8.34377336e-01\n",
      " 7.17577922e-06 2.12795459e-02 3.25971086e-05 9.20133736e-03\n",
      " 3.67121005e-02 1.32079417e-04]\n",
      "The last layer activations are: \n",
      "[1.33864917e-02 3.42656485e-03 3.69266550e-02 8.58242566e-01\n",
      " 7.43315337e-06 1.61432234e-02 3.37753955e-05 1.28124582e-02\n",
      " 1.42455702e-02 9.89640724e-05]\n",
      "The last layer activations are: \n",
      "[1.99695082e-02 2.21871419e-03 3.28379758e-02 8.65955012e-01\n",
      " 7.44917864e-06 2.90986470e-02 3.20462589e-05 1.12392555e-02\n",
      " 2.65016320e-02 1.26431655e-04]\n",
      "The last layer activations are: \n",
      "[1.32620251e-02 3.61013677e-03 3.21071719e-02 8.46614394e-01\n",
      " 7.16557576e-06 1.87017224e-02 3.24719835e-05 1.12143799e-02\n",
      " 1.67572708e-02 1.05340116e-04]\n",
      "The last layer activations are: \n",
      "[1.77446248e-02 2.45622290e-03 3.09685860e-02 8.68448862e-01\n",
      " 7.22416277e-06 2.53311132e-02 3.20591828e-05 1.06526048e-02\n",
      " 2.79343381e-02 1.18925075e-04]\n",
      "The last layer activations are: \n",
      "[1.15296905e-02 3.43350160e-03 2.84817475e-02 8.26655069e-01\n",
      " 6.65832725e-06 1.29085683e-02 2.93488531e-05 9.72995397e-03\n",
      " 3.35411465e-02 1.05123043e-04]\n",
      "The last layer activations are: \n",
      "[1.77768931e-02 2.42154557e-03 3.09866970e-02 8.77532268e-01\n",
      " 7.16509249e-06 2.62200181e-02 3.22505708e-05 1.06352840e-02\n",
      " 2.61139007e-02 1.16933111e-04]\n",
      "The last layer activations are: \n",
      "[1.09239178e-02 3.31836693e-03 2.97306157e-02 8.23668489e-01\n",
      " 6.56244277e-06 1.25964333e-02 3.03092633e-05 9.43233447e-03\n",
      " 3.55168714e-02 1.03778266e-04]\n",
      "The last layer activations are: \n",
      "[1.81308616e-02 2.39326242e-03 3.14317749e-02 8.85761216e-01\n",
      " 7.14541744e-06 3.08700609e-02 3.26640181e-05 1.05380726e-02\n",
      " 2.18367772e-02 1.20194107e-04]\n",
      "The last layer activations are: \n",
      "[9.41572380e-03 3.39556001e-03 3.14584792e-02 8.06584380e-01\n",
      " 6.41036615e-06 1.09397674e-02 3.21150642e-05 8.81786037e-03\n",
      " 3.98076726e-02 9.92040205e-05]\n",
      "The last layer activations are: \n",
      "[1.81194063e-02 2.37075053e-03 3.12088063e-02 8.87866425e-01\n",
      " 7.24427601e-06 4.17455721e-02 3.25572367e-05 9.64147226e-03\n",
      " 1.76062391e-02 1.34405765e-04]\n",
      "The last layer activations are: \n",
      "[7.64048517e-03 3.42803676e-03 4.00609422e-02 7.81170165e-01\n",
      " 6.41981183e-06 9.67072373e-03 4.09078541e-05 8.15120009e-03\n",
      " 4.16186612e-02 8.93777751e-05]\n",
      "The last layer activations are: \n",
      "[1.74569003e-02 2.47450390e-03 2.90017734e-02 8.86999326e-01\n",
      " 7.01647565e-06 4.26343378e-02 3.12554618e-05 9.08519624e-03\n",
      " 1.74175891e-02 1.38915772e-04]\n",
      "The last layer activations are: \n",
      "[2.65905269e-03 3.97018196e-03 1.26919736e-01 6.00867209e-01\n",
      " 7.55212564e-06 8.12258208e-03 1.41228991e-04 5.97342727e-03\n",
      " 2.95688420e-02 5.74966452e-05]\n",
      "The last layer activations are: \n",
      "[1.69960838e-02 2.51118018e-03 2.62589170e-02 8.81901168e-01\n",
      " 6.87979093e-06 4.58260161e-02 3.05134328e-05 8.26637443e-03\n",
      " 1.79293503e-02 1.48314744e-04]\n",
      "The last layer activations are: \n",
      "[2.46197330e-03 4.23561436e-03 1.34929229e-01 5.94993514e-01\n",
      " 7.42327756e-06 8.21065260e-03 1.53952672e-04 5.99914101e-03\n",
      " 2.40953549e-02 5.49251728e-05]\n",
      "The last layer activations are: \n",
      "[1.53971216e-02 2.72718297e-03 2.40022677e-02 8.68143795e-01\n",
      " 6.57136409e-06 4.69374190e-02 2.89439011e-05 7.14538022e-03\n",
      " 1.85493506e-02 1.59533104e-04]\n",
      "The last layer activations are: \n",
      "[4.12277445e-03 4.11048161e-03 7.27199042e-02 6.94695370e-01\n",
      " 6.58574763e-06 7.87903750e-03 8.05851581e-05 6.97083216e-03\n",
      " 2.88126292e-02 6.62289578e-05]\n",
      "The last layer activations are: \n",
      "[1.35812402e-02 2.55189509e-03 2.45514146e-02 8.46217714e-01\n",
      " 6.81817713e-06 6.06858750e-02 2.78083221e-05 5.45627680e-03\n",
      " 2.02781681e-02 2.06060035e-04]\n",
      "The last layer activations are: \n",
      "[6.84392136e-03 5.16645687e-03 3.20266353e-02 8.14967477e-01\n",
      " 6.02309266e-06 7.62540498e-03 3.09672929e-05 9.61962149e-03\n",
      " 1.92852113e-02 8.50460055e-05]\n",
      "The last layer activations are: \n",
      "[1.19653530e-02 2.40602480e-03 2.55664402e-02 8.20987000e-01\n",
      " 6.95744615e-06 7.02454906e-02 2.65569578e-05 4.56844873e-03\n",
      " 2.28536062e-02 2.42201589e-04]\n",
      "The last layer activations are: \n",
      "[4.55880728e-03 9.63764433e-03 2.48552642e-02 7.88410927e-01\n",
      " 6.36795078e-06 4.73941912e-03 2.21803622e-05 1.15037281e-02\n",
      " 8.60288619e-03 8.41002125e-05]\n",
      "The last layer activations are: \n",
      "[1.51533886e-02 2.00661046e-03 2.50496346e-02 8.52941764e-01\n",
      " 6.30421369e-06 1.76828507e-02 2.69514785e-05 8.77529153e-03\n",
      " 5.66012351e-02 1.19535041e-04]\n",
      "The last layer activations are: \n",
      "[7.19531912e-03 9.37099750e-03 2.34478155e-02 8.49670431e-01\n",
      " 5.28414589e-06 1.17321221e-02 2.16200613e-05 1.03083222e-02\n",
      " 4.35974831e-03 9.21860002e-05]\n",
      "The last layer activations are: \n",
      "[1.63524709e-02 1.96644530e-03 2.82149649e-02 8.53194846e-01\n",
      " 6.10652058e-06 1.86036523e-02 2.68679037e-05 1.03301299e-02\n",
      " 4.16329748e-02 1.22836532e-04]\n",
      "The last layer activations are: \n",
      "[1.23934414e-02 4.95073165e-03 2.56148448e-02 8.70125202e-01\n",
      " 5.64919894e-06 2.12943735e-02 3.31839694e-05 9.92548892e-03\n",
      " 6.78874763e-03 8.23368990e-05]\n",
      "The last layer activations are: \n",
      "[1.04751381e-02 2.85167297e-03 2.58109849e-02 8.27269476e-01\n",
      " 5.26255479e-06 9.94924698e-03 2.59939460e-05 8.74990026e-03\n",
      " 5.65586391e-02 9.99906960e-05]\n",
      "The last layer activations are: \n",
      "[1.67990336e-02 3.11118650e-03 3.07213583e-02 8.95316021e-01\n",
      " 5.85695947e-06 3.24898968e-02 3.86832534e-05 1.16978059e-02\n",
      " 8.23266718e-03 8.69984915e-05]\n",
      "The last layer activations are: \n",
      "[5.67300267e-03 4.11155234e-03 2.52171938e-02 6.93723662e-01\n",
      " 5.44160205e-06 4.42779887e-03 2.94254339e-05 7.57669541e-03\n",
      " 7.46024563e-02 8.16344572e-05]\n",
      "The last layer activations are: \n",
      "[2.10131625e-02 2.23410562e-03 3.71015624e-02 9.16271503e-01\n",
      " 6.30292372e-06 3.94954211e-02 4.07388714e-05 1.21381480e-02\n",
      " 1.19871605e-02 9.19528260e-05]\n",
      "The last layer activations are: \n",
      "[6.19906037e-03 4.91775006e-03 2.39216369e-02 7.52805595e-01\n",
      " 5.15017224e-06 5.35062293e-03 2.50606849e-05 7.98544537e-03\n",
      " 5.22428573e-02 8.62395230e-05]\n",
      "The last layer activations are: \n",
      "[1.89760697e-02 2.32114675e-03 3.51189988e-02 9.06416425e-01\n",
      " 6.11171990e-06 3.51884156e-02 3.72354172e-05 1.11450864e-02\n",
      " 1.65108260e-02 9.44201193e-05]\n",
      "The last layer activations are: \n",
      "[8.35493932e-03 5.08835621e-03 2.36413921e-02 8.25940237e-01\n",
      " 5.08731151e-06 1.03264136e-02 2.34438053e-05 9.10241066e-03\n",
      " 2.45457599e-02 9.09571430e-05]\n",
      "The last layer activations are: \n",
      "[1.41495639e-02 2.79902317e-03 3.04814212e-02 8.74857003e-01\n",
      " 5.59612021e-06 2.12286266e-02 3.17653382e-05 9.85076517e-03\n",
      " 2.54763968e-02 9.19631236e-05]\n",
      "The last layer activations are: \n",
      "[9.69768522e-03 4.21825899e-03 2.33917704e-02 8.38662369e-01\n",
      " 5.37509148e-06 1.22796025e-02 2.31677874e-05 9.70182236e-03\n",
      " 2.41738330e-02 9.63931800e-05]\n",
      "The last layer activations are: \n",
      "[1.26227751e-02 2.78428474e-03 3.09603372e-02 8.62829961e-01\n",
      " 5.46460014e-06 1.77882200e-02 3.23144673e-05 9.16409873e-03\n",
      " 3.03682808e-02 8.83267535e-05]\n",
      "The last layer activations are: \n",
      "[1.06804095e-02 4.20082086e-03 2.38262118e-02 8.60968445e-01\n",
      " 5.30556589e-06 1.61839164e-02 2.32857501e-05 9.98226875e-03\n",
      " 1.66076643e-02 9.82855307e-05]\n",
      "The last layer activations are: \n",
      "[1.03219032e-02 2.90196044e-03 3.37154224e-02 8.41418598e-01\n",
      " 5.37737955e-06 1.43967747e-02 3.50475476e-05 8.56170022e-03\n",
      " 3.34872970e-02 8.20744332e-05]\n",
      "The last layer activations are: \n",
      "[1.11474067e-02 4.18497431e-03 2.37681319e-02 8.73404921e-01\n",
      " 5.20464770e-06 1.88641853e-02 2.35472502e-05 9.83229042e-03\n",
      " 1.37221588e-02 9.83820786e-05]\n",
      "The last layer activations are: \n",
      "[9.07580342e-03 3.06867049e-03 3.64657313e-02 8.27194265e-01\n",
      " 5.28983596e-06 1.32561076e-02 3.72816169e-05 8.23709154e-03\n",
      " 3.18161456e-02 7.76226870e-05]\n",
      "The last layer activations are: \n",
      "[1.09007873e-02 4.23204543e-03 2.34329296e-02 8.74364443e-01\n",
      " 5.09885429e-06 1.83651731e-02 2.31374398e-05 9.70514508e-03\n",
      " 1.37021276e-02 9.61800790e-05]\n",
      "The last layer activations are: \n",
      "[9.93192958e-03 3.17562148e-03 3.16043130e-02 8.43384660e-01\n",
      " 5.05078384e-06 1.40866765e-02 3.17492080e-05 8.45965049e-03\n",
      " 2.88276232e-02 8.05971129e-05]\n",
      "The last layer activations are: \n",
      "[1.04992252e-02 4.23037316e-03 2.35180270e-02 8.71199306e-01\n",
      " 4.91821819e-06 1.62198503e-02 2.30330995e-05 9.49511920e-03\n",
      " 1.53245742e-02 8.98790812e-05]\n",
      "The last layer activations are: \n",
      "[1.12115043e-02 3.21545360e-03 2.66915688e-02 8.59997367e-01\n",
      " 4.99998399e-06 1.59818368e-02 2.65418038e-05 8.86584556e-03\n",
      " 2.46728959e-02 8.73749652e-05]\n",
      "The last layer activations are: \n",
      "[9.67910372e-03 4.15136825e-03 2.37035667e-02 8.58293440e-01\n",
      " 4.88098947e-06 1.35437677e-02 2.32004883e-05 9.18598042e-03\n",
      " 1.84941586e-02 8.56027150e-05]\n",
      "The last layer activations are: \n",
      "[1.15259908e-02 3.23354455e-03 2.56404910e-02 8.65941062e-01\n",
      " 4.88298832e-06 1.71741334e-02 2.59852652e-05 8.65294172e-03\n",
      " 2.27321358e-02 8.67919178e-05]\n",
      "The last layer activations are: \n",
      "[9.32700762e-03 4.23080566e-03 2.39372722e-02 8.55207808e-01\n",
      " 4.87275649e-06 1.34832778e-02 2.32252989e-05 9.15472951e-03\n",
      " 1.68457759e-02 8.48556712e-05]\n",
      "The last layer activations are: \n",
      "[1.12426990e-02 3.26486098e-03 2.50852125e-02 8.65013101e-01\n",
      " 4.73154463e-06 1.63841502e-02 2.57198561e-05 8.34935325e-03\n",
      " 2.34380917e-02 8.41954125e-05]\n",
      "The last layer activations are: \n",
      "[8.74129267e-03 4.48774216e-03 2.32184593e-02 8.50523084e-01\n",
      " 4.82033539e-06 1.24730186e-02 2.22860384e-05 9.10176333e-03\n",
      " 1.59674037e-02 8.51165758e-05]\n",
      "The last layer activations are: \n",
      "[1.16696022e-02 3.15103697e-03 2.53977774e-02 8.71848718e-01\n",
      " 4.63283186e-06 1.74569090e-02 2.62708252e-05 8.24042247e-03\n",
      " 2.25103986e-02 8.24570009e-05]\n",
      "The last layer activations are: \n",
      "[8.19550259e-03 4.91883373e-03 2.20846190e-02 8.47480408e-01\n",
      " 4.80340847e-06 1.20552505e-02 2.06501024e-05 9.32530927e-03\n",
      " 1.34827553e-02 8.78293546e-05]\n",
      "The last layer activations are: \n",
      "[1.16515413e-02 3.04547373e-03 2.60323173e-02 8.73453453e-01\n",
      " 4.55228721e-06 1.72709882e-02 2.69064760e-05 8.13618574e-03\n",
      " 2.31683248e-02 8.04148770e-05]\n",
      "The last layer activations are: \n",
      "[8.39660282e-03 5.01635076e-03 2.16371821e-02 8.54807358e-01\n",
      " 4.69541694e-06 1.30886203e-02 2.02560093e-05 9.35174180e-03\n",
      " 1.16398338e-02 8.82823765e-05]\n",
      "The last layer activations are: \n",
      "[1.07528492e-02 3.03475413e-03 2.63122875e-02 8.64086241e-01\n",
      " 4.47611184e-06 1.47351302e-02 2.71621899e-05 7.98648829e-03\n",
      " 2.65633361e-02 7.73143385e-05]\n",
      "The last layer activations are: \n",
      "[9.30168936e-03 4.70763352e-03 2.22550306e-02 8.69131970e-01\n",
      " 4.59288347e-06 1.64975128e-02 2.11842859e-05 9.34300068e-03\n",
      " 9.97519932e-03 8.82664480e-05]\n",
      "The last layer activations are: \n",
      "[9.06202399e-03 3.05188919e-03 2.52912356e-02 8.39686965e-01\n",
      " 4.34122674e-06 1.00180075e-02 2.63470676e-05 7.53728778e-03\n",
      " 4.04352682e-02 7.21679883e-05]\n",
      "The last layer activations are: \n",
      "[9.15282723e-03 4.81121318e-03 2.26353644e-02 8.71539516e-01\n",
      " 4.86821900e-06 1.97120789e-02 2.04749008e-05 1.00467509e-02\n",
      " 6.92408086e-03 9.73171561e-05]\n",
      "The last layer activations are: \n",
      "[7.05025140e-03 2.85394681e-03 3.29350155e-02 8.03132166e-01\n",
      " 4.51439611e-06 7.91055357e-03 3.42392736e-05 7.08648848e-03\n",
      " 4.71554586e-02 6.46418130e-05]\n",
      "The last layer activations are: \n",
      "[8.09309186e-03 5.35718027e-03 2.04046373e-02 8.61517898e-01\n",
      " 5.15097883e-06 1.57849410e-02 1.87083287e-05 1.10297985e-02\n",
      " 6.36103581e-03 1.00539378e-04]\n",
      "The last layer activations are: \n",
      "[7.29852432e-04 3.67450863e-03 3.98791406e-01 3.80707619e-01\n",
      " 7.50835748e-06 8.08356718e-03 6.01408227e-04 4.03015407e-03\n",
      " 1.41898864e-02 2.77283942e-05]\n",
      "The last layer activations are: \n",
      "[9.01938051e-03 5.16104220e-03 1.65157689e-02 8.77234927e-01\n",
      " 4.59266832e-06 1.75839146e-02 2.13249104e-05 9.50911790e-03\n",
      " 7.87059359e-03 8.92371882e-05]\n",
      "The last layer activations are: \n",
      "[2.16578375e-03 2.83935001e-03 1.80642399e-01 6.11702176e-01\n",
      " 6.69098262e-06 1.19028852e-02 2.24759917e-04 6.08249693e-03\n",
      " 1.70598010e-02 4.03104261e-05]\n",
      "The last layer activations are: \n",
      "[9.42214673e-03 5.29928366e-03 1.77694277e-02 8.84573560e-01\n",
      " 4.21026428e-06 1.83142009e-02 2.10657487e-05 9.29337573e-03\n",
      " 7.97387782e-03 8.38455800e-05]\n",
      "The last layer activations are: \n",
      "[7.85090974e-03 2.68117473e-03 4.75983937e-02 8.39073713e-01\n",
      " 4.64656183e-06 1.78430715e-02 4.84040128e-05 8.82177083e-03\n",
      " 1.92682804e-02 6.59143164e-05]\n",
      "The last layer activations are: \n",
      "[8.68828184e-03 5.79360995e-03 1.81300111e-02 8.83820102e-01\n",
      " 3.99283439e-06 1.47310835e-02 2.27533070e-05 9.58964048e-03\n",
      " 7.60559595e-03 6.98302835e-05]\n",
      "The last layer activations are: \n",
      "[1.05904887e-02 3.03746253e-03 2.84344365e-02 8.75676940e-01\n",
      " 4.12667237e-06 1.85000564e-02 2.71068749e-05 9.23550741e-03\n",
      " 1.92466827e-02 7.74724336e-05]\n",
      "The last layer activations are: \n",
      "[8.68565628e-03 5.44764985e-03 2.45958695e-02 8.85780210e-01\n",
      " 3.77993504e-06 1.41647380e-02 2.68017052e-05 9.36539194e-03\n",
      " 7.96599947e-03 6.02980422e-05]\n",
      "The last layer activations are: \n",
      "[8.28323911e-03 4.42527008e-03 1.96301061e-02 8.50152238e-01\n",
      " 3.59370461e-06 1.56793861e-02 1.83500389e-05 7.24118808e-03\n",
      " 2.00138133e-02 9.50449745e-05]\n",
      "The last layer activations are: \n",
      "[6.92441419e-03 5.61475684e-03 3.41759559e-02 8.73499956e-01\n",
      " 4.08065585e-06 1.17555694e-02 3.64812139e-05 9.42639603e-03\n",
      " 6.32474210e-03 4.60509548e-05]\n",
      "The last layer activations are: \n",
      "[8.70358070e-03 3.88660076e-03 1.99790915e-02 8.41001713e-01\n",
      " 4.16388637e-06 3.01073633e-02 2.00520930e-05 5.62614658e-03\n",
      " 1.55415651e-02 1.18715636e-04]\n",
      "The last layer activations are: \n",
      "[1.32455587e-04 7.59590948e-03 7.51870597e-01 1.57921999e-01\n",
      " 8.43997136e-06 3.32112173e-03 2.95013598e-03 2.38231268e-03\n",
      " 5.81747693e-03 1.03550153e-05]\n",
      "The last layer activations are: \n",
      "[9.96364513e-03 3.77767477e-03 1.94422959e-02 8.62842710e-01\n",
      " 3.98688218e-06 3.51557583e-02 2.32741559e-05 6.02194848e-03\n",
      " 1.33098363e-02 1.05466143e-04]\n",
      "The last layer activations are: \n",
      "[3.65035890e-04 6.41407859e-03 4.66532720e-01 2.75922235e-01\n",
      " 6.90258097e-06 4.25826458e-03 9.07945987e-04 3.09456174e-03\n",
      " 1.01896011e-02 1.59265891e-05]\n",
      "The last layer activations are: \n",
      "[1.27051542e-02 3.10789700e-03 2.14495249e-02 8.90121886e-01\n",
      " 4.31637174e-06 3.61753366e-02 2.46917436e-05 7.58528450e-03\n",
      " 1.34938586e-02 9.21770272e-05]\n",
      "The last layer activations are: \n",
      "[3.23683973e-03 4.98385271e-03 6.48541060e-02 7.03896403e-01\n",
      " 4.32218311e-06 7.96459142e-03 6.99699829e-05 5.81362676e-03\n",
      " 1.88618006e-02 4.08611454e-05]\n",
      "The last layer activations are: \n",
      "[1.26795736e-02 2.95780049e-03 2.27962636e-02 8.83265814e-01\n",
      " 4.31869572e-06 3.93610761e-02 2.43190108e-05 6.90013600e-03\n",
      " 1.52720917e-02 9.67619133e-05]\n",
      "The last layer activations are: \n",
      "[7.85388947e-03 4.51946690e-03 2.39614121e-02 8.39295266e-01\n",
      " 3.82801113e-06 1.09991903e-02 2.31221330e-05 7.89188918e-03\n",
      " 1.99218913e-02 6.40120683e-05]\n",
      "The last layer activations are: \n",
      "[1.29084896e-02 3.10650916e-03 2.44228190e-02 8.86930882e-01\n",
      " 4.02243316e-06 2.67775260e-02 2.36404039e-05 8.04025945e-03\n",
      " 1.63527213e-02 7.84600299e-05]\n",
      "The last layer activations are: \n",
      "[1.02654671e-02 3.83946824e-03 2.39835128e-02 8.68545151e-01\n",
      " 3.76663829e-06 1.63540480e-02 2.28048578e-05 8.07024141e-03\n",
      " 1.71956118e-02 6.73878941e-05]\n",
      "The last layer activations are: \n",
      "[1.07373675e-02 3.68292425e-03 2.25876963e-02 8.72075787e-01\n",
      " 3.74231324e-06 1.80510416e-02 2.16040116e-05 7.74749755e-03\n",
      " 1.79012208e-02 7.09854236e-05]\n",
      "The last layer activations are: \n",
      "[9.80240274e-03 4.03902847e-03 2.31739773e-02 8.70366762e-01\n",
      " 3.64535812e-06 1.56238068e-02 2.17503398e-05 7.73164502e-03\n",
      " 1.63312458e-02 6.70788423e-05]\n",
      "The last layer activations are: \n",
      "[9.85414672e-03 3.84378607e-03 2.18281030e-02 8.65687527e-01\n",
      " 3.61536016e-06 1.52157430e-02 2.06012993e-05 7.40322550e-03\n",
      " 1.95212462e-02 6.95956776e-05]\n",
      "The last layer activations are: \n",
      "[9.28069666e-03 4.28374234e-03 2.28173537e-02 8.69651623e-01\n",
      " 3.58237063e-06 1.49354716e-02 2.11881143e-05 7.56875231e-03\n",
      " 1.47140836e-02 6.70291180e-05]\n",
      "The last layer activations are: \n",
      "[9.20046147e-03 3.97100550e-03 2.10635897e-02 8.63028650e-01\n",
      " 3.47543138e-06 1.32060910e-02 1.98419166e-05 7.10513002e-03\n",
      " 2.13180770e-02 6.71520277e-05]\n",
      "The last layer activations are: \n",
      "[8.61184642e-03 4.62162899e-03 2.22505045e-02 8.67048409e-01\n",
      " 3.54471927e-06 1.41525828e-02 2.02892260e-05 7.54259111e-03\n",
      " 1.31592647e-02 6.71200692e-05]\n",
      "The last layer activations are: \n",
      "[8.65396093e-03 4.13127089e-03 2.08528737e-02 8.62277932e-01\n",
      " 3.28220109e-06 1.21325059e-02 1.97691956e-05 6.70235360e-03\n",
      " 2.24321297e-02 6.36409195e-05]\n",
      "The last layer activations are: \n",
      "[7.30605305e-03 5.52156762e-03 2.08594888e-02 8.59132241e-01\n",
      " 3.55678069e-06 1.22802254e-02 1.80929832e-05 7.80773935e-03\n",
      " 1.06642993e-02 6.87902074e-05]\n",
      "The last layer activations are: \n",
      "[8.95316267e-03 3.99283516e-03 2.12164250e-02 8.69448592e-01\n",
      " 3.12507394e-06 1.28450048e-02 2.02933918e-05 6.48600414e-03\n",
      " 2.28865868e-02 6.17719183e-05]\n",
      "The last layer activations are: \n",
      "[7.12496695e-03 5.92566283e-03 2.03428948e-02 8.61900890e-01\n",
      " 3.52225281e-06 1.29561680e-02 1.71752911e-05 8.18884149e-03\n",
      " 8.29043993e-03 7.07981461e-05]\n",
      "The last layer activations are: \n",
      "[8.11581162e-03 4.08091134e-03 2.10714229e-02 8.57389783e-01\n",
      " 3.07832086e-06 1.05430691e-02 1.98070777e-05 6.52895912e-03\n",
      " 2.56837812e-02 6.02287179e-05]\n",
      "The last layer activations are: \n",
      "[8.39219076e-03 5.25280968e-03 2.18400563e-02 8.79212121e-01\n",
      " 3.32456528e-06 1.72243536e-02 1.89248103e-05 7.96555733e-03\n",
      " 7.61615913e-03 6.91175240e-05]\n",
      "The last layer activations are: \n",
      "[6.79333000e-03 4.46502756e-03 2.08447155e-02 8.37732804e-01\n",
      " 3.10506366e-06 8.00029032e-03 1.91129835e-05 6.56523709e-03\n",
      " 2.69485233e-02 5.92562426e-05]\n",
      "The last layer activations are: \n",
      "[8.91898083e-03 4.68824219e-03 2.13540833e-02 8.80269617e-01\n",
      " 3.29114829e-06 1.69802578e-02 1.90351821e-05 7.70889272e-03\n",
      " 1.00008418e-02 6.92619711e-05]\n",
      "The last layer activations are: \n",
      "[7.10880896e-03 4.68199099e-03 2.18579563e-02 8.55559174e-01\n",
      " 3.00299383e-06 1.00916008e-02 2.01064039e-05 6.56012980e-03\n",
      " 1.99577809e-02 5.80978884e-05]\n",
      "The last layer activations are: \n",
      "[7.28242636e-03 5.33652108e-03 1.90675211e-02 8.65362331e-01\n",
      " 3.18347210e-06 1.14953472e-02 1.68486910e-05 7.52978717e-03\n",
      " 1.24842263e-02 6.64196379e-05]\n",
      "The last layer activations are: \n",
      "[8.07898159e-03 4.37261511e-03 2.20010217e-02 8.70195972e-01\n",
      " 2.99073067e-06 1.26669173e-02 2.03557744e-05 6.71505329e-03\n",
      " 1.66720221e-02 5.93323886e-05]\n",
      "The last layer activations are: \n",
      "[6.66274893e-03 5.51788104e-03 1.86471920e-02 8.53660596e-01\n",
      " 3.06107174e-06 9.82319323e-03 1.68138772e-05 7.05571365e-03\n",
      " 1.41649063e-02 6.25463367e-05]\n",
      "The last layer activations are: \n",
      "[8.26232653e-03 4.40671862e-03 2.09920706e-02 8.73055448e-01\n",
      " 2.94864656e-06 1.34024437e-02 1.95974492e-05 6.67605294e-03\n",
      " 1.53825837e-02 6.01825984e-05]\n",
      "The last layer activations are: \n",
      "[6.66790311e-03 5.43662565e-03 1.86713938e-02 8.54433505e-01\n",
      " 2.97605922e-06 9.65461958e-03 1.70473648e-05 6.86072998e-03\n",
      " 1.45032799e-02 6.03067566e-05]\n",
      "The last layer activations are: \n",
      "[8.32474040e-03 4.36704446e-03 2.06436623e-02 8.74804614e-01\n",
      " 2.91266051e-06 1.37234048e-02 1.95125649e-05 6.58454944e-03\n",
      " 1.49423555e-02 5.98370068e-05]\n",
      "The last layer activations are: \n",
      "[6.60267451e-03 5.43420550e-03 1.83762014e-02 8.55207236e-01\n",
      " 2.95670790e-06 9.40438981e-03 1.67452466e-05 6.89508225e-03\n",
      " 1.42436859e-02 6.01806831e-05]\n",
      "The last layer activations are: \n",
      "[8.50436277e-03 4.21790912e-03 2.07143685e-02 8.77360343e-01\n",
      " 2.86155586e-06 1.41406108e-02 1.97609862e-05 6.46604187e-03\n",
      " 1.51033227e-02 5.93853668e-05]\n",
      "The last layer activations are: \n",
      "[6.42163757e-03 5.57880985e-03 1.79795605e-02 8.54150667e-01\n",
      " 2.94220480e-06 9.12696781e-03 1.62669318e-05 6.96394261e-03\n",
      " 1.34711489e-02 6.07349232e-05]\n",
      "The last layer activations are: \n",
      "[8.62381869e-03 4.05332986e-03 2.08806519e-02 8.78593434e-01\n",
      " 2.81909829e-06 1.42955844e-02 2.01118170e-05 6.36520800e-03\n",
      " 1.56439885e-02 5.88079487e-05]\n",
      "The last layer activations are: \n",
      "[6.36059452e-03 5.72095100e-03 1.76336650e-02 8.55465233e-01\n",
      " 2.92508393e-06 9.23324542e-03 1.58417833e-05 7.05840408e-03\n",
      " 1.23350786e-02 6.16036719e-05]\n",
      "The last layer activations are: \n",
      "[8.51431870e-03 3.90077816e-03 2.11672255e-02 8.76905177e-01\n",
      " 2.77003382e-06 1.35630936e-02 2.06106059e-05 6.25350945e-03\n",
      " 1.73324995e-02 5.66963017e-05]\n",
      "The last layer activations are: \n",
      "[6.14203939e-03 6.15640190e-03 1.70186682e-02 8.56949553e-01\n",
      " 2.88664989e-06 9.33194272e-03 1.49646961e-05 7.22060532e-03\n",
      " 1.05797736e-02 6.31793615e-05]\n",
      "The last layer activations are: \n",
      "[8.47469402e-03 3.72594372e-03 2.17865689e-02 8.76561619e-01\n",
      " 2.73234365e-06 1.30754895e-02 2.11896756e-05 6.24699629e-03\n",
      " 1.89593609e-02 5.45082642e-05]\n",
      "The last layer activations are: \n",
      "[6.10521332e-03 6.32621690e-03 1.67401459e-02 8.59019242e-01\n",
      " 2.86279733e-06 9.67416207e-03 1.44450360e-05 7.38167899e-03\n",
      " 9.59811047e-03 6.43477379e-05]\n",
      "The last layer activations are: \n",
      "[7.90242423e-03 3.78882591e-03 2.28200572e-02 8.70436848e-01\n",
      " 2.74440058e-06 1.21542223e-02 2.16323281e-05 6.37422884e-03\n",
      " 1.85572466e-02 5.32981421e-05]\n",
      "The last layer activations are: \n",
      "[6.81565528e-03 5.70946917e-03 1.69970942e-02 8.71343281e-01\n",
      " 2.66012407e-06 1.07077731e-02 1.55095147e-05 6.85720799e-03\n",
      " 1.10966514e-02 5.99628352e-05]\n",
      "The last layer activations are: \n",
      "[7.40781957e-03 4.26081534e-03 2.19061675e-02 8.70037829e-01\n",
      " 2.62564031e-06 1.15865824e-02 2.04739455e-05 6.27062583e-03\n",
      " 1.61496754e-02 5.24369787e-05]\n",
      "The last layer activations are: \n",
      "[7.38103576e-03 5.19083490e-03 1.75337404e-02 8.78025105e-01\n",
      " 2.50945951e-06 1.16112530e-02 1.65947940e-05 6.34252778e-03\n",
      " 1.26130304e-02 5.58366944e-05]\n",
      "The last layer activations are: \n",
      "[7.24446562e-03 4.61485087e-03 2.01685093e-02 8.72286387e-01\n",
      " 2.53324336e-06 1.12581978e-02 1.87720994e-05 6.23289093e-03\n",
      " 1.46093060e-02 5.25301690e-05]\n",
      "The last layer activations are: \n",
      "[7.60248644e-03 4.88289978e-03 1.82048435e-02 8.79089441e-01\n",
      " 2.48639834e-06 1.23046747e-02 1.72053770e-05 6.29260450e-03\n",
      " 1.25930231e-02 5.50410080e-05]\n",
      "The last layer activations are: \n",
      "[7.31174659e-03 4.65618658e-03 1.94465531e-02 8.74670094e-01\n",
      " 2.46491321e-06 1.11926736e-02 1.83471787e-05 6.16461248e-03\n",
      " 1.42695745e-02 5.19054255e-05]\n",
      "The last layer activations are: \n",
      "[7.74972561e-03 4.74771539e-03 1.80597807e-02 8.80766845e-01\n",
      " 2.45928260e-06 1.26414880e-02 1.71583296e-05 6.26918522e-03\n",
      " 1.24466158e-02 5.50216156e-05]\n",
      "The last layer activations are: \n",
      "[7.33948014e-03 4.55041463e-03 1.93403280e-02 8.75051994e-01\n",
      " 2.42250204e-06 1.10117276e-02 1.83873495e-05 6.08430173e-03\n",
      " 1.47216588e-02 5.10751889e-05]\n",
      "The last layer activations are: \n",
      "[7.84401562e-03 4.68596543e-03 1.79093158e-02 8.82661829e-01\n",
      " 2.41696492e-06 1.28090111e-02 1.70818372e-05 6.22616998e-03\n",
      " 1.22734106e-02 5.46710358e-05]\n",
      "The last layer activations are: \n",
      "[7.36185102e-03 4.41051478e-03 1.95177761e-02 8.75465541e-01\n",
      " 2.38256908e-06 1.09582047e-02 1.86194480e-05 6.00237222e-03\n",
      " 1.52374613e-02 5.02561251e-05]\n",
      "The last layer activations are: \n",
      "[7.70287848e-03 4.77356188e-03 1.75671471e-02 8.83016115e-01\n",
      " 2.37238179e-06 1.24964607e-02 1.67250400e-05 6.21489917e-03\n",
      " 1.19631175e-02 5.44427118e-05]\n",
      "The last layer activations are: \n",
      "[7.41191282e-03 4.21262651e-03 2.00273593e-02 8.76121241e-01\n",
      " 2.34675683e-06 1.10653725e-02 1.91278662e-05 5.91413650e-03\n",
      " 1.59759257e-02 4.93794649e-05]\n",
      "The last layer activations are: \n",
      "[7.14653434e-03 5.17257371e-03 1.68844125e-02 8.79708358e-01\n",
      " 2.34772522e-06 1.14227869e-02 1.57219734e-05 6.28327748e-03\n",
      " 1.12339967e-02 5.48942128e-05]\n",
      "The last layer activations are: \n",
      "[7.46173977e-03 3.91841067e-03 2.12034800e-02 8.76592547e-01\n",
      " 2.32850430e-06 1.14718940e-02 2.02176366e-05 5.77584338e-03\n",
      " 1.72720658e-02 4.86922087e-05]\n",
      "The last layer activations are: \n",
      "[6.88063441e-03 5.60864075e-03 1.62535941e-02 8.82616194e-01\n",
      " 2.30908831e-06 1.11934360e-02 1.48102558e-05 6.40883444e-03\n",
      " 9.81990238e-03 5.56931933e-05]\n",
      "The last layer activations are: \n",
      "[7.05118714e-03 3.35918911e-03 2.57144358e-02 8.65150620e-01\n",
      " 2.45074198e-06 1.10716251e-02 2.41536202e-05 5.79786871e-03\n",
      " 2.09566709e-02 4.52154594e-05]\n",
      "The last layer activations are: \n",
      "[6.59770640e-03 6.10323466e-03 1.55284882e-02 8.82570346e-01\n",
      " 2.40891785e-06 1.23760186e-02 1.34750438e-05 6.77486406e-03\n",
      " 7.46347741e-03 6.17480462e-05]\n",
      "The last layer activations are: \n",
      "[2.29290351e-04 4.22520383e-03 5.79606788e-01 2.06872539e-01\n",
      " 5.64676586e-06 5.11037646e-03 1.06930648e-03 2.17633950e-03\n",
      " 1.30928599e-02 1.34624899e-05]\n",
      "The last layer activations are: \n",
      "[5.99657243e-03 6.48933673e-03 1.36742602e-02 8.71892481e-01\n",
      " 2.75298691e-06 1.49305605e-02 1.14951518e-05 7.23885349e-03\n",
      " 5.23202941e-03 8.20593695e-05]\n",
      "The last layer activations are: \n",
      "[2.23625315e-05 4.23753919e-03 9.54644473e-01 2.79712923e-02\n",
      " 1.07370745e-05 3.03001308e-03 1.53311827e-02 1.20331868e-03\n",
      " 9.96482899e-03 6.16051107e-06]\n",
      "The last layer activations are: \n",
      "[5.72074574e-03 7.89272509e-03 1.01030769e-02 8.77541892e-01\n",
      " 2.33500665e-06 2.82937486e-02 1.13904166e-05 4.46981715e-03\n",
      " 4.94407357e-03 9.42020246e-05]\n",
      "The last layer activations are: \n",
      "[2.79530020e-05 3.26781625e-03 9.51357678e-01 3.21099086e-02\n",
      " 1.22198041e-05 3.41659343e-03 1.49726131e-02 1.52154724e-03\n",
      " 9.53842732e-03 6.72847436e-06]\n",
      "The last layer activations are: \n",
      "[1.99269746e-03 5.53463393e-02 6.37127788e-03 8.25297528e-01\n",
      " 2.04471685e-06 4.87312540e-03 5.92555794e-06 6.92699944e-03\n",
      " 1.44976264e-03 7.79104870e-05]\n",
      "The last layer activations are: \n",
      "[1.63216784e-02 1.86673220e-03 3.32340195e-02 9.33656252e-01\n",
      " 2.77741631e-06 3.67069335e-02 2.77587209e-05 9.74573559e-03\n",
      " 1.13745362e-02 6.07333536e-05]\n",
      "The last layer activations are: \n",
      "[4.23000318e-03 1.45099734e-02 1.06910751e-02 8.32701936e-01\n",
      " 2.24250870e-06 7.87250724e-03 1.03469277e-05 7.15040263e-03\n",
      " 5.99139174e-03 6.87704009e-05]\n",
      "The last layer activations are: \n",
      "[1.46246981e-02 2.77312233e-03 2.63831521e-02 9.27651771e-01\n",
      " 2.69486437e-06 2.95674777e-02 2.46274746e-05 9.58100050e-03\n",
      " 9.20747981e-03 5.85562009e-05]\n",
      "The last layer activations are: \n",
      "[7.82698215e-03 5.26747723e-03 1.52267800e-02 8.61432672e-01\n",
      " 2.44793270e-06 1.40838006e-02 1.54726032e-05 6.48667859e-03\n",
      " 1.38536109e-02 6.37809071e-05]\n",
      "The last layer activations are: \n",
      "[8.92791987e-03 4.42972460e-03 2.94313744e-02 9.02216215e-01\n",
      " 2.40134156e-06 1.45095663e-02 2.62620254e-05 8.63721153e-03\n",
      " 7.81159621e-03 4.26953922e-05]\n",
      "The last layer activations are: \n",
      "[8.36620493e-03 3.68298010e-03 1.60863027e-02 8.33820922e-01\n",
      " 2.84768130e-06 2.89189927e-02 1.61916514e-05 4.47511275e-03\n",
      " 1.61592645e-02 9.54212020e-05]\n",
      "The last layer activations are: \n",
      "[7.42958829e-03 4.83822015e-03 3.01514230e-02 8.81138566e-01\n",
      " 2.60457167e-06 9.99953096e-03 2.59497303e-05 8.81354566e-03\n",
      " 6.76134276e-03 3.92369603e-05]\n",
      "The last layer activations are: \n",
      "[1.41264538e-02 2.33993665e-03 2.31513614e-02 8.89963038e-01\n",
      " 3.03717930e-06 3.60296256e-02 2.08554723e-05 7.64303244e-03\n",
      " 1.25199714e-02 7.44683107e-05]\n",
      "The last layer activations are: \n",
      "[8.07763351e-03 3.82854466e-03 2.83792250e-02 8.53276501e-01\n",
      " 2.77328600e-06 1.10994584e-02 2.62387659e-05 7.73097229e-03\n",
      " 1.23859942e-02 4.13906634e-05]\n",
      "The last layer activations are: \n",
      "[1.09672114e-02 2.46133869e-03 2.16484977e-02 8.65650237e-01\n",
      " 2.96527451e-06 4.57295600e-02 1.65050024e-05 5.56382124e-03\n",
      " 1.42228383e-02 1.00811197e-04]\n",
      "The last layer activations are: \n",
      "[5.98361845e-03 4.85438944e-03 2.66437812e-02 8.19048368e-01\n",
      " 2.77890113e-06 8.35169495e-03 2.59103182e-05 6.81616853e-03\n",
      " 1.24528128e-02 3.50018251e-05]\n",
      "The last layer activations are: \n",
      "[9.53662722e-03 2.44771953e-03 2.26007886e-02 8.68416830e-01\n",
      " 3.03322518e-06 5.09491184e-02 1.40121338e-05 5.10219496e-03\n",
      " 1.49264738e-02 1.01415846e-04]\n",
      "The last layer activations are: \n",
      "[5.86114880e-03 5.74356820e-03 2.87720288e-02 7.95687512e-01\n",
      " 2.68645829e-06 8.36713637e-03 2.48035493e-05 6.87275018e-03\n",
      " 8.41720203e-03 3.41532202e-05]\n",
      "The last layer activations are: \n",
      "[1.02573328e-02 2.49997362e-03 2.26851695e-02 8.60794321e-01\n",
      " 2.92661933e-06 5.08300521e-02 1.53717005e-05 4.83728843e-03\n",
      " 1.38708248e-02 9.42434019e-05]\n",
      "The last layer activations are: \n",
      "[5.36408179e-03 5.03282944e-03 3.84932646e-02 8.25736181e-01\n",
      " 2.48229530e-06 9.22179754e-03 3.20759301e-05 6.48390368e-03\n",
      " 9.83516314e-03 3.05027851e-05]\n",
      "The last layer activations are: \n",
      "[1.05918159e-02 2.88949702e-03 1.98343346e-02 8.66404368e-01\n",
      " 2.80047024e-06 4.13723144e-02 1.70467231e-05 4.94012653e-03\n",
      " 1.28437536e-02 8.15753413e-05]\n",
      "The last layer activations are: \n",
      "[3.97590102e-03 4.64169892e-03 4.91173660e-02 7.85150313e-01\n",
      " 2.61670274e-06 7.79689136e-03 4.11966761e-05 5.75314939e-03\n",
      " 1.36294484e-02 2.93204102e-05]\n",
      "The last layer activations are: \n",
      "[1.20586144e-02 2.98514288e-03 2.13277131e-02 9.06376554e-01\n",
      " 2.50643894e-06 2.71978630e-02 1.85327804e-05 6.97697255e-03\n",
      " 1.23703305e-02 5.71012109e-05]\n",
      "The last layer activations are: \n",
      "[8.96318842e-03 3.67178946e-03 2.02392572e-02 8.77862692e-01\n",
      " 2.34021942e-06 1.17383356e-02 1.72828140e-05 7.40214691e-03\n",
      " 1.78333950e-02 4.40956243e-05]\n",
      "The last layer activations are: \n",
      "[1.11649414e-02 3.18677193e-03 2.16893388e-02 8.96031379e-01\n",
      " 2.38103736e-06 2.05937731e-02 1.79145013e-05 7.20003567e-03\n",
      " 1.36219250e-02 5.06222026e-05]\n",
      "The last layer activations are: \n",
      "[8.40283118e-03 4.01204073e-03 1.96390897e-02 8.77829307e-01\n",
      " 2.20377909e-06 1.20955724e-02 1.64168769e-05 6.79164968e-03\n",
      " 1.62283761e-02 4.43343663e-05]\n",
      "The last layer activations are: \n",
      "[9.96935501e-03 3.50054232e-03 2.01339168e-02 8.93584048e-01\n",
      " 2.24697489e-06 1.72004542e-02 1.69536305e-05 6.73914271e-03\n",
      " 1.42516436e-02 4.87547904e-05]\n",
      "The last layer activations are: \n",
      "[7.70232021e-03 4.16696911e-03 1.88191802e-02 8.73166867e-01\n",
      " 2.15987923e-06 1.07818279e-02 1.58509974e-05 6.42043031e-03\n",
      " 1.70429146e-02 4.44633349e-05]\n",
      "The last layer activations are: \n",
      "[1.00004087e-02 3.43641661e-03 2.03336099e-02 8.95855218e-01\n",
      " 2.22621703e-06 1.93990415e-02 1.71437163e-05 6.26895323e-03\n",
      " 1.33558558e-02 5.08134633e-05]\n",
      "The last layer activations are: \n",
      "[7.38294695e-03 4.32980186e-03 1.81862730e-02 8.76037217e-01\n",
      " 2.09068301e-06 1.01059940e-02 1.53832919e-05 6.20473815e-03\n",
      " 1.69214598e-02 4.43240681e-05]\n",
      "The last layer activations are: \n",
      "[9.77285295e-03 3.49300866e-03 2.00205625e-02 8.98362853e-01\n",
      " 2.15701886e-06 1.90858612e-02 1.71031593e-05 6.03238549e-03\n",
      " 1.31568506e-02 5.04165772e-05]\n",
      "The last layer activations are: \n",
      "[7.14014309e-03 4.48243090e-03 1.76121214e-02 8.78176979e-01\n",
      " 2.01091484e-06 9.82985605e-03 1.50680384e-05 5.90553046e-03\n",
      " 1.66765115e-02 4.40959175e-05]\n",
      "The last layer activations are: \n",
      "[9.21886707e-03 3.74129208e-03 1.94892829e-02 8.99816814e-01\n",
      " 2.05370459e-06 1.71787649e-02 1.67930849e-05 5.92554426e-03\n",
      " 1.26781642e-02 4.78093794e-05]\n",
      "The last layer activations are: \n",
      "[7.34110950e-03 4.22101621e-03 1.73843115e-02 8.79746666e-01\n",
      " 1.98625644e-06 1.01905990e-02 1.51159767e-05 5.74227918e-03\n",
      " 1.79982324e-02 4.40370730e-05]\n",
      "The last layer activations are: \n",
      "[8.68498489e-03 3.98266407e-03 1.86483764e-02 8.97897945e-01\n",
      " 1.97540439e-06 1.58175758e-02 1.62513476e-05 5.78189730e-03\n",
      " 1.25778278e-02 4.64077511e-05]\n",
      "The last layer activations are: \n",
      "[7.39868128e-03 4.16943939e-03 1.74888658e-02 8.83521760e-01\n",
      " 1.93316529e-06 1.07736599e-02 1.53106164e-05 5.61144913e-03\n",
      " 1.75449854e-02 4.35536873e-05]\n",
      "The last layer activations are: \n",
      "[8.57076301e-03 4.06461858e-03 1.81571273e-02 9.00197222e-01\n",
      " 1.91960785e-06 1.57761511e-02 1.60368968e-05 5.67732273e-03\n",
      " 1.21746892e-02 4.57107348e-05]\n",
      "The last layer activations are: \n",
      "[7.05150636e-03 4.27376621e-03 1.72472378e-02 8.81908942e-01\n",
      " 1.86897511e-06 1.03350946e-02 1.51385389e-05 5.42542147e-03\n",
      " 1.78453264e-02 4.25682251e-05]\n",
      "The last layer activations are: \n",
      "[8.51545615e-03 4.10676798e-03 1.78960100e-02 9.02658281e-01\n",
      " 1.86919265e-06 1.56824459e-02 1.59069523e-05 5.62042991e-03\n",
      " 1.18407959e-02 4.49437747e-05]\n",
      "The last layer activations are: \n",
      "[6.97095498e-03 4.27577064e-03 1.72661000e-02 8.83078071e-01\n",
      " 1.81455644e-06 1.05842002e-02 1.52153166e-05 5.27303260e-03\n",
      " 1.75131029e-02 4.19556713e-05]\n",
      "The last layer activations are: \n",
      "[8.03405188e-03 4.34051229e-03 1.71903024e-02 9.01052513e-01\n",
      " 1.81721645e-06 1.40417704e-02 1.52404018e-05 5.61747006e-03\n",
      " 1.17610774e-02 4.42912863e-05]\n",
      "The last layer activations are: \n",
      "[7.18443714e-03 4.06382219e-03 1.76632704e-02 8.86909678e-01\n",
      " 1.78165639e-06 1.14704314e-02 1.56531321e-05 5.17941692e-03\n",
      " 1.73689846e-02 4.21712079e-05]\n",
      "The last layer activations are: \n",
      "[7.32820118e-03 4.79540550e-03 1.62934535e-02 8.97388119e-01\n",
      " 1.77083686e-06 1.23027403e-02 1.42508938e-05 5.65568034e-03\n",
      " 1.09744269e-02 4.44636281e-05]\n",
      "The last layer activations are: \n",
      "[6.93289137e-03 3.85518551e-03 1.79016461e-02 8.82602781e-01\n",
      " 1.75852738e-06 1.07897560e-02 1.59208751e-05 5.01851509e-03\n",
      " 2.05704440e-02 4.15803603e-05]\n",
      "The last layer activations are: \n",
      "[7.23103064e-03 5.03979394e-03 1.63646679e-02 9.00835469e-01\n",
      " 1.76625264e-06 1.30236835e-02 1.38554901e-05 6.03709686e-03\n",
      " 8.67166340e-03 4.50278474e-05]\n",
      "The last layer activations are: \n",
      "[6.38912468e-03 3.77005789e-03 1.73325785e-02 8.67586429e-01\n",
      " 1.74347926e-06 8.45271235e-03 1.53085631e-05 5.07785217e-03\n",
      " 2.69909302e-02 3.94235693e-05]\n",
      "The last layer activations are: \n",
      "[6.43122320e-03 5.70323343e-03 1.67321622e-02 8.95489195e-01\n",
      " 1.85960951e-06 1.30427102e-02 1.29564927e-05 6.80358895e-03\n",
      " 5.90945129e-03 4.90471213e-05]\n",
      "The last layer activations are: \n",
      "[6.19546514e-03 3.40593361e-03 1.78054641e-02 8.55985541e-01\n",
      " 1.79178954e-06 7.75266284e-03 1.56093500e-05 4.98592480e-03\n",
      " 3.20582769e-02 4.04654738e-05]\n",
      "The last layer activations are: \n",
      "[7.03717613e-03 5.28718528e-03 1.86533527e-02 9.05732175e-01\n",
      " 1.79454864e-06 1.26618204e-02 1.42110590e-05 7.25666186e-03\n",
      " 5.62281828e-03 4.32857798e-05]\n",
      "The last layer activations are: \n",
      "[4.78624497e-03 4.34636523e-03 1.50055913e-02 8.27221680e-01\n",
      " 1.66658081e-06 5.30942536e-03 1.26508059e-05 4.64323252e-03\n",
      " 3.40469875e-02 4.11436136e-05]\n",
      "The last layer activations are: \n",
      "[9.16078016e-03 4.07335027e-03 2.26583228e-02 9.25679129e-01\n",
      " 1.70243732e-06 1.57168148e-02 1.85054813e-05 6.86681348e-03\n",
      " 5.81741779e-03 3.88178840e-05]\n",
      "The last layer activations are: \n",
      "[4.79781129e-03 4.76521431e-03 1.64923677e-02 8.42968441e-01\n",
      " 1.62293627e-06 6.34790610e-03 1.32591500e-05 4.62740155e-03\n",
      " 2.36870989e-02 4.42942922e-05]\n",
      "The last layer activations are: \n",
      "[8.05039954e-03 3.65538643e-03 2.48067348e-02 9.08734113e-01\n",
      " 1.88446898e-06 1.24091810e-02 2.16636842e-05 7.05657940e-03\n",
      " 8.20304520e-03 3.46071479e-05]\n",
      "The last layer activations are: \n",
      "[6.01031612e-03 4.63585513e-03 1.63291271e-02 8.69645660e-01\n",
      " 1.61268530e-06 1.03695718e-02 1.16737316e-05 5.44263676e-03\n",
      " 1.59363667e-02 4.98900842e-05]\n",
      "The last layer activations are: \n",
      "[5.87808865e-03 4.78621237e-03 2.33588890e-02 8.87428624e-01\n",
      " 1.69696836e-06 7.45481186e-03 2.26078531e-05 5.46831753e-03\n",
      " 1.10029735e-02 2.81854439e-05]\n",
      "The last layer activations are: \n",
      "[7.88880141e-03 3.77883516e-03 1.92208997e-02 9.10992827e-01\n",
      " 1.67598694e-06 1.74104125e-02 1.49813554e-05 5.57746509e-03\n",
      " 1.17348436e-02 4.73485536e-05]\n",
      "The last layer activations are: \n",
      "[4.79946725e-03 5.46800198e-03 1.61319325e-02 8.60752475e-01\n",
      " 1.62128730e-06 4.77631859e-03 1.53557701e-05 5.29463372e-03\n",
      " 1.96106243e-02 3.03961771e-05]\n",
      "The last layer activations are: \n",
      "[8.63964928e-03 3.63734002e-03 1.84944185e-02 9.04196157e-01\n",
      " 1.69993333e-06 1.67688186e-02 1.54500984e-05 5.72180855e-03\n",
      " 1.27609117e-02 4.41705333e-05]\n",
      "The last layer activations are: \n",
      "[4.24360108e-03 5.19456916e-03 1.63054930e-02 8.34490613e-01\n",
      " 1.68076004e-06 4.82145944e-03 1.42463754e-05 5.02857541e-03\n",
      " 2.47370953e-02 3.32616795e-05]\n",
      "The last layer activations are: \n",
      "[8.05923502e-03 3.95777635e-03 1.72090503e-02 9.05699056e-01\n",
      " 1.62348417e-06 1.57123654e-02 1.47837493e-05 5.30273552e-03\n",
      " 1.32726331e-02 4.21284271e-05]\n",
      "The last layer activations are: \n",
      "[4.44097166e-03 5.36850763e-03 1.57513019e-02 8.47269283e-01\n",
      " 1.56848673e-06 5.64686586e-03 1.34134323e-05 4.78271212e-03\n",
      " 2.22799658e-02 3.44742110e-05]\n",
      "The last layer activations are: \n",
      "[6.64103518e-03 4.65688876e-03 1.58774029e-02 8.95014880e-01\n",
      " 1.49996535e-06 1.14874900e-02 1.35765492e-05 4.98649439e-03\n",
      " 1.46288112e-02 3.88937004e-05]\n",
      "The last layer activations are: \n",
      "[5.04950431e-03 5.21998424e-03 1.48104369e-02 8.67697906e-01\n",
      " 1.49472297e-06 6.97155552e-03 1.28075177e-05 4.73118320e-03\n",
      " 1.97144217e-02 3.61043683e-05]\n",
      "The last layer activations are: \n",
      "[5.97629280e-03 4.99357912e-03 1.53634314e-02 8.91149073e-01\n",
      " 1.43687925e-06 9.98402604e-03 1.33007202e-05 4.74509398e-03\n",
      " 1.50340176e-02 3.70450659e-05]\n",
      "The last layer activations are: \n",
      "[5.39267121e-03 5.27715539e-03 1.45794567e-02 8.80992063e-01\n",
      " 1.42033926e-06 8.28054085e-03 1.25845488e-05 4.64396722e-03\n",
      " 1.66758202e-02 3.63208749e-05]\n",
      "The last layer activations are: \n",
      "[6.16448811e-03 4.86540601e-03 1.56242822e-02 8.96498856e-01\n",
      " 1.40997564e-06 1.08813806e-02 1.34926743e-05 4.75056723e-03\n",
      " 1.38159235e-02 3.67159802e-05]\n",
      "The last layer activations are: \n",
      "[5.16807454e-03 5.41286152e-03 1.41462585e-02 8.80341454e-01\n",
      " 1.37500988e-06 7.81907291e-03 1.21871738e-05 4.57473225e-03\n",
      " 1.68173709e-02 3.55453900e-05]\n",
      "The last layer activations are: \n",
      "[6.29760559e-03 4.80706756e-03 1.57239192e-02 9.00810361e-01\n",
      " 1.37275067e-06 1.19042794e-02 1.35927009e-05 4.70512719e-03\n",
      " 1.27360051e-02 3.65855895e-05]\n",
      "The last layer activations are: \n",
      "[4.95262010e-03 5.55247176e-03 1.38762930e-02 8.79408595e-01\n",
      " 1.33122820e-06 7.44498838e-03 1.19608523e-05 4.49435486e-03\n",
      " 1.68178304e-02 3.47606939e-05]\n",
      "The last layer activations are: \n",
      "[6.24577253e-03 4.83101624e-03 1.55324670e-02 9.02404170e-01\n",
      " 1.33256014e-06 1.22252207e-02 1.34515017e-05 4.62103895e-03\n",
      " 1.23575912e-02 3.63364417e-05]\n",
      "The last layer activations are: \n",
      "[4.95272336e-03 5.57027556e-03 1.39100238e-02 8.82329382e-01\n",
      " 1.29230148e-06 7.65829123e-03 1.20236341e-05 4.44827554e-03\n",
      " 1.59712563e-02 3.41650318e-05]\n",
      "The last layer activations are: \n",
      "[6.09948951e-03 4.88990398e-03 1.52039932e-02 9.02366576e-01\n",
      " 1.29374067e-06 1.18978713e-02 1.31845231e-05 4.54845016e-03\n",
      " 1.24343065e-02 3.57873087e-05]\n",
      "The last layer activations are: \n",
      "[5.05123373e-03 5.52700351e-03 1.39948731e-02 8.86166187e-01\n",
      " 1.26045715e-06 8.14265290e-03 1.21149908e-05 4.43515811e-03\n",
      " 1.48707106e-02 3.38463062e-05]\n",
      "The last layer activations are: \n",
      "[6.07856904e-03 4.87081388e-03 1.51025164e-02 9.03268185e-01\n",
      " 1.26462715e-06 1.19381809e-02 1.30992227e-05 4.52239914e-03\n",
      " 1.22277981e-02 3.53242728e-05]\n",
      "The last layer activations are: \n",
      "[4.99089441e-03 5.56706430e-03 1.38487970e-02 8.86681264e-01\n",
      " 1.22823998e-06 8.11537845e-03 1.19945883e-05 4.39741381e-03\n",
      " 1.45624013e-02 3.33734749e-05]\n",
      "The last layer activations are: \n",
      "[6.10615008e-03 4.83887257e-03 1.50576870e-02 9.04641940e-01\n",
      " 1.23783572e-06 1.23130298e-02 1.30709123e-05 4.48696986e-03\n",
      " 1.18278766e-02 3.50773482e-05]\n",
      "The last layer activations are: \n",
      "[4.87714775e-03 5.55210988e-03 1.36515328e-02 8.85034897e-01\n",
      " 1.20332041e-06 7.79881937e-03 1.18415212e-05 4.35507517e-03\n",
      " 1.50860211e-02 3.28054058e-05]\n",
      "The last layer activations are: \n",
      "[6.14747163e-03 4.81600561e-03 1.50313230e-02 9.06605673e-01\n",
      " 1.21101191e-06 1.28147076e-02 1.30592294e-05 4.44746318e-03\n",
      " 1.13482642e-02 3.48884460e-05]\n",
      "The last layer activations are: \n",
      "[4.73207220e-03 5.52068462e-03 1.34657136e-02 8.82278724e-01\n",
      " 1.18086545e-06 7.38079162e-03 1.16931251e-05 4.30016048e-03\n",
      " 1.60197538e-02 3.21880609e-05]\n",
      "The last layer activations are: \n",
      "[6.16540928e-03 4.82159319e-03 1.49896569e-02 9.08763151e-01\n",
      " 1.18254096e-06 1.31827499e-02 1.30318800e-05 4.41450225e-03\n",
      " 1.08928803e-02 3.45429167e-05]\n",
      "The last layer activations are: \n",
      "[4.63596755e-03 5.51452006e-03 1.34031182e-02 8.81488632e-01\n",
      " 1.15490571e-06 7.18867314e-03 1.16271574e-05 4.25052181e-03\n",
      " 1.63898448e-02 3.15880689e-05]\n",
      "The last layer activations are: \n",
      "[6.05825254e-03 4.91440290e-03 1.47920075e-02 9.09498071e-01\n",
      " 1.14822178e-06 1.29773246e-02 1.28749272e-05 4.36564424e-03\n",
      " 1.06909402e-02 3.38867154e-05]\n",
      "The last layer activations are: \n",
      "[4.68502853e-03 5.47452021e-03 1.35049114e-02 8.84591282e-01\n",
      " 1.12828844e-06 7.44160638e-03 1.17001153e-05 4.23489429e-03\n",
      " 1.57804308e-02 3.11504722e-05]\n",
      "The last layer activations are: \n",
      "[5.80129482e-03 5.08808792e-03 1.43818161e-02 9.08068770e-01\n",
      " 1.10915519e-06 1.20230012e-02 1.25490722e-05 4.29144447e-03\n",
      " 1.09632828e-02 3.29139402e-05]\n",
      "The last layer activations are: \n",
      "[4.90067945e-03 5.40405123e-03 1.37162795e-02 8.91368702e-01\n",
      " 1.10199975e-06 8.24339100e-03 1.18732933e-05 4.25742324e-03\n",
      " 1.41477243e-02 3.09878427e-05]\n",
      "The last layer activations are: \n",
      "[5.68662601e-03 5.07863941e-03 1.41621736e-02 9.07028450e-01\n",
      " 1.08638618e-06 1.14657124e-02 1.23648399e-05 4.25931768e-03\n",
      " 1.14064502e-02 3.22683237e-05]\n",
      "The last layer activations are: \n",
      "[4.88734973e-03 5.44367214e-03 1.35879055e-02 8.92616158e-01\n",
      " 1.07843575e-06 8.37025473e-03 1.17603667e-05 4.24357944e-03\n",
      " 1.35450065e-02 3.06788114e-05]\n",
      "The last layer activations are: \n",
      "[5.87924181e-03 4.84231560e-03 1.44231892e-02 9.09365612e-01\n",
      " 1.08212319e-06 1.23108649e-02 1.25527009e-05 4.28723344e-03\n",
      " 1.11047772e-02 3.23296129e-05]\n",
      "The last layer activations are: \n",
      "[4.57751697e-03 5.57544838e-03 1.31567444e-02 8.87388912e-01\n",
      " 1.05658844e-06 7.48222218e-03 1.13969836e-05 4.17285560e-03\n",
      " 1.45574155e-02 2.99799970e-05]\n",
      "The last layer activations are: \n",
      "[5.96547598e-03 4.78077338e-03 1.45091057e-02 9.11835911e-01\n",
      " 1.06307424e-06 1.31846644e-02 1.26154280e-05 4.23805661e-03\n",
      " 1.05200961e-02 3.24224338e-05]\n",
      "The last layer activations are: \n",
      "[4.31944627e-03 5.64166171e-03 1.28586941e-02 8.82500344e-01\n",
      " 1.03698956e-06 6.81094604e-03 1.11439326e-05 4.09498737e-03\n",
      " 1.57660258e-02 2.93834061e-05]\n",
      "The last layer activations are: \n",
      "[5.95178129e-03 4.82015193e-03 1.44741986e-02 9.14088278e-01\n",
      " 1.03642804e-06 1.35885912e-02 1.25992698e-05 4.18877703e-03\n",
      " 1.00418374e-02 3.21153251e-05]\n",
      "The last layer activations are: \n",
      "[4.18852807e-03 5.63239306e-03 1.27524938e-02 8.80589439e-01\n",
      " 1.01742154e-06 6.54311164e-03 1.10584602e-05 4.03319690e-03\n",
      " 1.65451846e-02 2.88521513e-05]\n",
      "The last layer activations are: \n",
      "[5.80791016e-03 4.93451687e-03 1.43439381e-02 9.15319256e-01\n",
      " 1.01075939e-06 1.34401095e-02 1.25047998e-05 4.16631777e-03\n",
      " 9.72529460e-03 3.14608211e-05]\n",
      "The last layer activations are: \n",
      "[4.22984272e-03 5.55181770e-03 1.26662815e-02 8.82819921e-01\n",
      " 9.99075606e-07 6.65186646e-03 1.10234071e-05 3.99098642e-03\n",
      " 1.67774475e-02 2.84544760e-05]\n",
      "The last layer activations are: \n",
      "[5.63000460e-03 5.07422063e-03 1.41386718e-02 9.14756165e-01\n",
      " 9.87181710e-07 1.27763824e-02 1.22634472e-05 4.14158989e-03\n",
      " 9.71102862e-03 3.06687482e-05]\n",
      "The last layer activations are: \n",
      "[4.41178056e-03 5.44034037e-03 1.28892455e-02 8.89201588e-01\n",
      " 9.79912116e-07 7.19806954e-03 1.11832490e-05 4.00048442e-03\n",
      " 1.57080116e-02 2.81423386e-05]\n",
      "The last layer activations are: \n",
      "[5.24585019e-03 5.34434481e-03 1.35190471e-02 9.10819293e-01\n",
      " 9.56415023e-07 1.11639993e-02 1.17193875e-05 4.05798623e-03\n",
      " 1.03482918e-02 2.97277672e-05]\n",
      "The last layer activations are: \n",
      "[4.80516454e-03 5.24694140e-03 1.33203019e-02 8.99001337e-01\n",
      " 9.64267794e-07 8.45272428e-03 1.15378354e-05 4.05933839e-03\n",
      " 1.35072306e-02 2.81357814e-05]\n",
      "The last layer activations are: \n",
      "[5.15598304e-03 5.17709354e-03 1.33395116e-02 9.08596729e-01\n",
      " 9.51322033e-07 1.03359804e-02 1.15159603e-05 4.06730430e-03\n",
      " 1.14680755e-02 2.92222319e-05]\n",
      "The last layer activations are: \n",
      "[4.84737754e-03 5.30348315e-03 1.31539949e-02 9.01100603e-01\n",
      " 9.45343482e-07 8.74851626e-03 1.14054464e-05 4.04172966e-03\n",
      " 1.25918497e-02 2.79463197e-05]\n",
      "The last layer activations are: \n",
      "[5.17909844e-03 5.00438401e-03 1.34218538e-02 9.07967608e-01\n",
      " 9.47962338e-07 1.03309064e-02 1.15032760e-05 4.08605146e-03\n",
      " 1.16914983e-02 2.89434608e-05]\n",
      "The last layer activations are: \n",
      "[4.71166937e-03 5.41169367e-03 1.29236771e-02 9.00737210e-01\n",
      " 9.25448824e-07 8.38280270e-03 1.11937307e-05 4.00191891e-03\n",
      " 1.24656473e-02 2.74344420e-05]\n",
      "The last layer activations are: \n",
      "[5.30021486e-03 4.85174773e-03 1.35336415e-02 9.09278283e-01\n",
      " 9.40310119e-07 1.07547644e-02 1.15690598e-05 4.07339308e-03\n",
      " 1.14985435e-02 2.88258973e-05]\n",
      "The last layer activations are: \n",
      "[4.55264628e-03 5.45942804e-03 1.27586486e-02 8.98387617e-01\n",
      " 9.13183477e-07 7.94828821e-03 1.09821557e-05 3.97638242e-03\n",
      " 1.27149768e-02 2.71354333e-05]\n",
      "The last layer activations are: \n",
      "[5.52761447e-03 4.69026723e-03 1.37450046e-02 9.12701158e-01\n",
      " 9.31036344e-07 1.16799211e-02 1.17498939e-05 4.06006227e-03\n",
      " 1.09291545e-02 2.88763083e-05]\n",
      "The last layer activations are: \n",
      "[4.33959808e-03 5.52080974e-03 1.25675645e-02 8.93934421e-01\n",
      " 9.01926160e-07 7.35566391e-03 1.07268645e-05 3.93586457e-03\n",
      " 1.33613382e-02 2.68129894e-05]\n",
      "The last layer activations are: \n",
      "[5.56158108e-03 4.64366451e-03 1.38806624e-02 9.15362737e-01\n",
      " 9.14916036e-07 1.23710571e-02 1.17947388e-05 4.00906187e-03\n",
      " 1.04535859e-02 2.89294938e-05]\n",
      "The last layer activations are: \n",
      "[4.16845624e-03 5.64384108e-03 1.22396979e-02 8.91598995e-01\n",
      " 8.84223015e-07 6.91488330e-03 1.04361858e-05 3.87068495e-03\n",
      " 1.37547299e-02 2.64670559e-05]\n",
      "The last layer activations are: \n",
      "[5.60125595e-03 4.62699176e-03 1.38481781e-02 9.16410972e-01\n",
      " 8.97478640e-07 1.24468005e-02 1.17525843e-05 3.94523487e-03\n",
      " 1.03786390e-02 2.86144642e-05]\n",
      "The last layer activations are: \n",
      "[4.07925274e-03 5.70096682e-03 1.21388457e-02 8.90495096e-01\n",
      " 8.68838567e-07 6.73956542e-03 1.02714759e-05 3.82801796e-03\n",
      " 1.37937068e-02 2.61939085e-05]\n",
      "Label for the data is: 6\n",
      "The last layer activations are: \n",
      "[1.54195446e-02 1.64180231e-03 3.20660804e-02 3.40695646e-05\n",
      " 1.00819861e-02 3.38719179e-03 9.49377746e-01 5.45723087e-06\n",
      " 1.18282815e-02 4.14435059e-08]\n",
      "The cost is: 0.00040843329486013504\n",
      "Label for the data is: 6\n",
      "The last layer activations are: \n",
      "[3.14548638e-03 6.56969192e-03 2.02519138e-02 2.21690958e-05\n",
      " 3.83671761e-03 3.08067799e-03 8.55724798e-01 1.58990079e-06\n",
      " 8.66200260e-03 7.20578499e-08]\n",
      "The cost is: 0.002137777062994092\n",
      "Label for the data is: 3\n",
      "The last layer activations are: \n",
      "[1.05728955e-02 1.56283137e-03 1.96100508e-02 9.16202407e-01\n",
      " 1.52354901e-06 2.60416095e-02 1.46784580e-05 6.05598683e-03\n",
      " 1.46186939e-02 4.20199862e-05]\n",
      "The cost is: 0.0008449367837459422\n",
      "Label for the data is: 4\n",
      "The last layer activations are: \n",
      "[1.10796271e-05 5.45507366e-03 5.31508465e-03 3.76700215e-09\n",
      " 9.82651291e-01 3.32267334e-04 1.18780267e-02 3.19177904e-04\n",
      " 1.57876298e-04 1.60120537e-03]\n",
      "The cost is: 5.0287434163401955e-05\n",
      "Label for the data is: 3\n",
      "The last layer activations are: \n",
      "[1.00260549e-02 2.50638717e-03 2.04169535e-02 9.45297076e-01\n",
      " 1.17587167e-06 2.45678299e-02 1.66737182e-05 5.83525080e-03\n",
      " 9.05920706e-03 3.13939911e-05]\n",
      "The cost is: 0.0004235764511675349\n",
      "Label for the data is: 3\n",
      "The last layer activations are: \n",
      "[4.90636579e-04 1.93006248e-03 5.89713996e-03 1.11793697e-01\n",
      " 5.48651656e-06 8.79571996e-01 1.59214568e-06 3.27740393e-05\n",
      " 1.47171165e-02 7.80160327e-03]\n",
      "The cost is: 0.15628735348952708\n",
      "Label for the data is: 2\n",
      "The last layer activations are: \n",
      "[2.93135976e-05 2.09126558e-03 9.43681492e-01 2.84954432e-02\n",
      " 8.59305287e-06 5.32711329e-03 1.00832677e-02 1.15725861e-03\n",
      " 7.00238257e-03 4.89610663e-06]\n",
      "The cost is: 0.0004168562062959365\n",
      "Label for the data is: 9\n",
      "The last layer activations are: \n",
      "[1.89635687e-06 3.20622553e-03 2.80246333e-03 9.31330316e-05\n",
      " 2.00013925e-02 5.22642906e-02 4.67768444e-09 3.03250758e-02\n",
      " 2.18279475e-04 9.56730373e-01]\n",
      "The cost is: 0.0005941672655944587\n",
      "Label for the data is: 7\n",
      "The last layer activations are: \n",
      "[9.09282349e-05 2.82671418e-03 1.45422279e-02 2.58554306e-02\n",
      " 4.13522390e-03 8.37316785e-05 7.97036551e-08 9.53751835e-01\n",
      " 9.90366157e-05 3.58453086e-02]\n",
      "The cost is: 0.00043288740268665916\n",
      "Label for the data is: 3\n",
      "The last layer activations are: \n",
      "[9.19930750e-03 2.93183456e-03 1.96190588e-02 9.46731404e-01\n",
      " 1.07910506e-06 2.20108177e-02 1.63471461e-05 5.50941560e-03\n",
      " 8.69957498e-03 2.91929389e-05]\n",
      "The cost is: 0.00039061872091402544\n",
      "Label for the data is: 5\n",
      "The last layer activations are: \n",
      "[2.72837346e-04 2.08351122e-03 4.22375883e-03 4.52975231e-02\n",
      " 6.88568127e-06 9.48266111e-01 1.01472761e-06 1.16651488e-05\n",
      " 1.53911331e-02 1.95755065e-02]\n",
      "The cost is: 0.000537060403145354\n",
      "Label for the data is: 6\n",
      "The last layer activations are: \n",
      "[1.36511322e-02 1.72850219e-03 2.74069362e-02 3.13488081e-05\n",
      " 9.68428682e-03 4.06702212e-03 9.34204544e-01 4.49901224e-06\n",
      " 1.26381542e-02 5.42758848e-08]\n",
      "The cost is: 0.0005539573334403335\n",
      "Label for the data is: 6\n",
      "The last layer activations are: \n",
      "[7.17200340e-03 7.02694528e-03 5.15728915e-03 2.35582091e-05\n",
      " 5.25992782e-03 5.07799159e-03 7.44475261e-01 1.07667272e-06\n",
      " 9.02651453e-03 1.15502854e-07]\n",
      "The cost is: 0.0065555236997723145\n",
      "Label for the data is: 3\n",
      "The last layer activations are: \n",
      "[1.54381834e-02 1.12259102e-03 2.60914996e-02 9.32327783e-01\n",
      " 1.75313080e-06 3.66768119e-02 1.92507311e-05 8.41850601e-03\n",
      " 1.07730160e-02 4.07899359e-05]\n",
      "The cost is: 0.0007032012642204233\n",
      "Label for the data is: 9\n",
      "The last layer activations are: \n",
      "[9.88006339e-07 3.69712756e-03 2.78375527e-03 4.70201961e-05\n",
      " 2.15789970e-02 2.37367026e-02 4.55635800e-09 2.55241836e-02\n",
      " 4.26920334e-04 9.53002193e-01]\n",
      "The cost is: 0.00039109644720540325\n",
      "Label for the data is: 1\n",
      "The last layer activations are: \n",
      "[1.57754004e-09 9.99979311e-01 3.17696507e-05 5.42187379e-04\n",
      " 3.38333301e-09 2.43770557e-09 4.05873975e-08 1.96638559e-06\n",
      " 7.91138338e-05 1.12357350e-06]\n",
      "The cost is: 3.0166861057841074e-08\n",
      "Label for the data is: 2\n",
      "The last layer activations are: \n",
      "[1.69300272e-05 2.08127210e-03 9.68856718e-01 1.72522042e-02\n",
      " 9.64430163e-06 4.62045317e-03 1.67087090e-02 1.03634353e-03\n",
      " 6.75715704e-03 4.23471970e-06]\n",
      "The cost is: 0.0001619137398217485\n",
      "Label for the data is: 0\n",
      "The last layer activations are: \n",
      "[9.60816276e-01 4.87998421e-04 3.39839076e-05 2.61126341e-02\n",
      " 2.49454973e-03 2.94840254e-02 2.66562224e-02 7.06090992e-05\n",
      " 2.10152018e-02 3.75988893e-07]\n",
      "The cost is: 0.0004245201617816851\n",
      "Label for the data is: 4\n",
      "The last layer activations are: \n",
      "[1.99971154e-03 3.23071564e-03 1.24168200e-04 1.27631858e-06\n",
      " 9.03809016e-01 2.49211222e-04 3.11074378e-04 7.02529019e-03\n",
      " 1.84393893e-04 1.31607828e-03]\n",
      "The cost is: 0.0009318436895320832\n",
      "Label for the data is: 5\n",
      "The last layer activations are: \n",
      "[4.63223259e-04 1.14445311e-03 4.13765611e-03 3.33855372e-02\n",
      " 1.22554477e-05 9.58043252e-01 1.44271488e-06 1.37760051e-05\n",
      " 1.89630614e-02 2.02755330e-02]\n",
      "The cost is: 0.00036643026593227604\n",
      "Testing on batch data:\n",
      "Average cost is:  0.013384029011417884\n",
      "Percentage of correct is:  0.917\n",
      "Testing on test data:\n",
      "Average cost is:  0.016305933312822218\n",
      "Percentage of correct is:  0.9008\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset: 28 x 28 = 784\n",
    "import pickle\n",
    "\n",
    "with open(\"network.pickle\", \"rb\") as infile:\n",
    "    net = pickle.load(infile)\n",
    "\n",
    "# net = Network(4, 3, 3, 2)\n",
    "# net = Network(784, 16, 16, 10)\n",
    "\n",
    "# Network is loaded into net\n",
    "\n",
    "training = True\n",
    "testing = False\n",
    "\n",
    "if training:\n",
    "    # #\n",
    "    # # 4 3 3 2 Test run\n",
    "    # #\n",
    "\n",
    "    # dummyData = [[0.125, 0.25, 0.675, 0.885]]\n",
    "    # dummyLabel = [1]\n",
    "\n",
    "    # for i in range(100):\n",
    "    #     net.trainBatch(dummyData, dummyLabel, 5)\n",
    "    #     net.coutLastLayer()\n",
    "    \n",
    "    # net.test(dummyData, dummyLabel)\n",
    "\n",
    "    # #\n",
    "    # # Training on the actual data\n",
    "    # #\n",
    "\n",
    "    with open(\"dataset/pickled/data_batch_01.pickle\", \"rb\") as infile:\n",
    "        data_batch_01 = pickle.load(infile)\n",
    "    with open(\"dataset/pickled/label_batch_01.pickle\", \"rb\") as infile:\n",
    "        label_batch_01 = pickle.load(infile)\n",
    "    with open(\"dataset/pickled/data_batch_02.pickle\", \"rb\") as infile:\n",
    "        data_batch_02 = pickle.load(infile)\n",
    "    with open(\"dataset/pickled/label_batch_02.pickle\", \"rb\") as infile:\n",
    "        label_batch_02 = pickle.load(infile)\n",
    "    with open(\"dataset/pickled/data_batch_03.pickle\", \"rb\") as infile:\n",
    "        data_batch_03 = pickle.load(infile)\n",
    "    with open(\"dataset/pickled/label_batch_03.pickle\", \"rb\") as infile:\n",
    "        label_batch_03 = pickle.load(infile)\n",
    "    with open(\"dataset/pickled/data_batch_04.pickle\", \"rb\") as infile:\n",
    "        data_batch_04 = pickle.load(infile)\n",
    "    with open(\"dataset/pickled/label_batch_04.pickle\", \"rb\") as infile:\n",
    "        label_batch_04 = pickle.load(infile)\n",
    "    with open(\"dataset/pickled/data_batch_05.pickle\", \"rb\") as infile:\n",
    "        data_batch_05 = pickle.load(infile)\n",
    "    with open(\"dataset/pickled/label_batch_05.pickle\", \"rb\") as infile:\n",
    "        label_batch_05 = pickle.load(infile)\n",
    "\n",
    "    # with open(\"dataset/pickled/data_batch_first_100.pickle\", \"rb\") as infile:\n",
    "    #     data_batch_first_100 = pickle.load(infile)\n",
    "    # with open(\"dataset/pickled/label_batch_first_100.pickle\", \"rb\") as infile:\n",
    "    #     label_batch_first_100 = pickle.load(infile)\n",
    "\n",
    "    with open(\"dataset/pickled/data_test.pickle\", \"rb\") as infile:\n",
    "        data_test = pickle.load(infile)\n",
    "    with open(\"dataset/pickled/label_test.pickle\", \"rb\") as infile:\n",
    "        label_test = pickle.load(infile)\n",
    "\n",
    "    print(\"Testing on batch data:\")\n",
    "    net.test(data_batch_03, label_batch_03)\n",
    "    print(\"Testing on test data:\")\n",
    "    net.test(data_test, label_test)\n",
    "\n",
    "    print(\"Testing on the batch\")\n",
    "    for i in range(200):\n",
    "        # Number in one batch is 6000 so a learning rate of 6000 will result in an npm of 1\n",
    "        net.trainBatch(data_batch_03, label_batch_03, 60)\n",
    "        net.coutLastLayer()\n",
    "        # net.cout()\n",
    "        \n",
    "        # net.test(data_batch_01, label_batch_01)\n",
    "        #net.test(data_test, label_test)\n",
    "\n",
    "    net.checkRandomExamples(data_test, data_test)\n",
    "\n",
    "    print(\"Testing on batch data:\")\n",
    "    net.test(data_batch_03, label_batch_03)\n",
    "    print(\"Testing on test data:\")\n",
    "    net.test(data_test, label_test)\n",
    "\n",
    "    with open(\"network.pickle\", \"wb\") as outfile:\n",
    "        pickle.dump(net, outfile)\n",
    "\n",
    "    # #\n",
    "    # #\n",
    "    # ### CHECKING\n",
    "    # #\n",
    "    # #\n",
    "\n",
    "    # \n",
    "\n",
    "if testing:\n",
    "    with open(\"dataset/pickled/data_test.pickle\", \"rb\") as infile:\n",
    "        data_test = pickle.load(infile)\n",
    "    with open(\"dataset/pickled/label_test.pickle\", \"rb\") as infile:\n",
    "        label_test = pickle.load(infile)\n",
    "\n",
    "    net.test(data_test, label_test)\n",
    "    net.checkRandomExamples(data_test, label_test)\n",
    "\n",
    "    net.cout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
